{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a86cebfb-ea96-46c2-8d22-a2aa78405033",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "488b2e0c-3ee1-44b9-a272-1c103344cf58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-22 13:01:04.387019: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-22 13:01:04.854995: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-03-22 13:01:04.855040: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-03-22 13:01:04.855044: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from evaluate import load\n",
    "\n",
    "wer_metric = load(\"wer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d09a3e1-208e-4d72-baae-02d90707b932",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dffdf6ea-d960-4b5c-ad2b-cc3455debe94",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json.load(open('annotations/captions_train2014.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "178db287-e4a7-478a-ba2a-8f0f1be350dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "414113"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data['annotations'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbefe774-f02b-4eda-8b7f-d2e91a0ceabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2filename = {i['id']:i['file_name'] for i in data['images']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a535ca91-10d4-42bc-af88-9e51b7b97b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data['annotations'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f6209f4-cc4a-4f74-b5a7-413113fdf98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['file_name'] = df['image_id'].map(id2filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00010f23-2d47-490c-a5b8-a6a715455ffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>id</th>\n",
       "      <th>caption</th>\n",
       "      <th>file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>318556</td>\n",
       "      <td>48</td>\n",
       "      <td>A very clean and well decorated empty bathroom</td>\n",
       "      <td>COCO_train2014_000000318556.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>116100</td>\n",
       "      <td>67</td>\n",
       "      <td>A panoramic view of a kitchen and all of its a...</td>\n",
       "      <td>COCO_train2014_000000116100.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>318556</td>\n",
       "      <td>126</td>\n",
       "      <td>A blue and white bathroom with butterfly theme...</td>\n",
       "      <td>COCO_train2014_000000318556.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>116100</td>\n",
       "      <td>148</td>\n",
       "      <td>A panoramic photo of a kitchen and dining room</td>\n",
       "      <td>COCO_train2014_000000116100.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>379340</td>\n",
       "      <td>173</td>\n",
       "      <td>A graffiti-ed stop sign across the street from...</td>\n",
       "      <td>COCO_train2014_000000379340.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414108</th>\n",
       "      <td>133071</td>\n",
       "      <td>829655</td>\n",
       "      <td>a slice of bread is covered with a sour cream ...</td>\n",
       "      <td>COCO_train2014_000000133071.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414109</th>\n",
       "      <td>410182</td>\n",
       "      <td>829658</td>\n",
       "      <td>A long plate hold some fries with some sliders...</td>\n",
       "      <td>COCO_train2014_000000410182.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414110</th>\n",
       "      <td>180285</td>\n",
       "      <td>829665</td>\n",
       "      <td>Two women sit and pose with stuffed animals.</td>\n",
       "      <td>COCO_train2014_000000180285.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414111</th>\n",
       "      <td>133071</td>\n",
       "      <td>829693</td>\n",
       "      <td>White Plate with a lot of guacamole and an ext...</td>\n",
       "      <td>COCO_train2014_000000133071.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414112</th>\n",
       "      <td>133071</td>\n",
       "      <td>829717</td>\n",
       "      <td>A dinner plate has a lemon wedge garnishment.</td>\n",
       "      <td>COCO_train2014_000000133071.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>414113 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        image_id      id                                            caption  \\\n",
       "0         318556      48     A very clean and well decorated empty bathroom   \n",
       "1         116100      67  A panoramic view of a kitchen and all of its a...   \n",
       "2         318556     126  A blue and white bathroom with butterfly theme...   \n",
       "3         116100     148     A panoramic photo of a kitchen and dining room   \n",
       "4         379340     173  A graffiti-ed stop sign across the street from...   \n",
       "...          ...     ...                                                ...   \n",
       "414108    133071  829655  a slice of bread is covered with a sour cream ...   \n",
       "414109    410182  829658  A long plate hold some fries with some sliders...   \n",
       "414110    180285  829665       Two women sit and pose with stuffed animals.   \n",
       "414111    133071  829693  White Plate with a lot of guacamole and an ext...   \n",
       "414112    133071  829717      A dinner plate has a lemon wedge garnishment.   \n",
       "\n",
       "                              file_name  \n",
       "0       COCO_train2014_000000318556.jpg  \n",
       "1       COCO_train2014_000000116100.jpg  \n",
       "2       COCO_train2014_000000318556.jpg  \n",
       "3       COCO_train2014_000000116100.jpg  \n",
       "4       COCO_train2014_000000379340.jpg  \n",
       "...                                 ...  \n",
       "414108  COCO_train2014_000000133071.jpg  \n",
       "414109  COCO_train2014_000000410182.jpg  \n",
       "414110  COCO_train2014_000000180285.jpg  \n",
       "414111  COCO_train2014_000000133071.jpg  \n",
       "414112  COCO_train2014_000000133071.jpg  \n",
       "\n",
       "[414113 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81c81d69-a021-4563-ac3b-771465d603da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44535\n"
     ]
    }
   ],
   "source": [
    "words = sorted(list(set(' '.join(df['caption']).split())))\n",
    "print(len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b761f0f-0a74-4f64-b2de-66e1d50cb3ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44536\n"
     ]
    }
   ],
   "source": [
    "vocabulary = [\"[PAD]\"] + words\n",
    "print(len(vocabulary))\n",
    "idx2word = {k:v for k,v in enumerate(vocabulary, start=0)}\n",
    "word2idx = {v:k for k,v in idx2word.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf93ac46-8415-4d1f-b9d1-deca6521a491",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df, test_size=0.1)\n",
    "train_df.reset_index(drop=True, inplace=True)\n",
    "test_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e41cf255-5924-4952-9b4a-3186aa18ef8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageCaptioningDataset(Dataset):\n",
    "    def __init__(self, root_dir, df, max_target_length=128):\n",
    "        self.root_dir = root_dir\n",
    "        self.df = df\n",
    "        self.max_target_length = max_target_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_name = self.df['file_name'][idx]\n",
    "        text = self.df['caption'][idx]\n",
    "        image = Image.open(self.root_dir + file_name).convert(\"RGB\")\n",
    "        image = self.transform(image)\n",
    "        return image, text\n",
    "    \n",
    "    def transform(self, image):\n",
    "        \n",
    "        transform_ops = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "        ])\n",
    "        return transform_ops(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62e5e3e3-e553-45ce-b371-930a6f10a531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2912 324\n"
     ]
    }
   ],
   "source": [
    "train_dataset = ImageCaptioningDataset(root_dir='train2014/',\n",
    "                           df=train_df)\n",
    "eval_dataset = ImageCaptioningDataset(root_dir='train2014/',\n",
    "                           df=test_df)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, num_workers=10, shuffle=True)\n",
    "test_loader = DataLoader(eval_dataset, batch_size=batch_size, num_workers=10, shuffle=False)\n",
    "print(len(train_loader), len(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f0debf98-90d8-4e2a-9bb0-fac2bea612c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44536\n"
     ]
    }
   ],
   "source": [
    "num_words = len(word2idx)\n",
    "print(num_words)\n",
    "rnn_hidden_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5f815d3-f2b6-491e-b9e6-9202afd947a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = resnet50(weights=ResNet50_Weights.IMAGENET1K_V1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f055fb1f-4e7a-413a-839c-f838d1bc538f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CRNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_words, rnn_hidden_size=256, dropout=0.1):\n",
    "        \n",
    "        super(CRNN, self).__init__()\n",
    "        self.num_cwords = num_words\n",
    "        self.rnn_hidden_size = rnn_hidden_size\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        resnet_modules = list(resnet.children())[:-3]\n",
    "        self.cnn = nn.Sequential(\n",
    "            *resnet_modules\n",
    "        )\n",
    "        \n",
    "        self.linear1 = nn.Linear(14336, rnn_hidden_size, bias=False)\n",
    "        \n",
    "        self.rnn1 = nn.GRU(input_size=rnn_hidden_size, \n",
    "                            hidden_size=rnn_hidden_size,\n",
    "                            bidirectional=True, \n",
    "                            batch_first=True)\n",
    "        self.rnn2 = nn.GRU(input_size=rnn_hidden_size*2, \n",
    "                            hidden_size=rnn_hidden_size*2,\n",
    "                            bidirectional=True, \n",
    "                            batch_first=True)\n",
    "        self.linear2 = nn.Linear(self.rnn_hidden_size*4, num_words)\n",
    "        \n",
    "    def forward(self, batch):\n",
    "        \n",
    "        batch = self.cnn(batch)\n",
    "        \n",
    "        batch = batch.permute(0, 3, 1, 2) # [batch_size, width, channels, height]\n",
    "         \n",
    "        batch_size = batch.size(0)\n",
    "        width = batch.size(1)\n",
    "        batch = batch.view(batch_size, width, -1) # [batch_size, T==width, num_features==channels*height]\n",
    "        \n",
    "        batch = self.linear1(batch)\n",
    "        \n",
    "        batch, hidden = self.rnn1(batch)\n",
    "        \n",
    "        batch, hidden = self.rnn2(batch)\n",
    "        \n",
    "        batch = self.linear2(batch)\n",
    "        \n",
    "        batch = batch.permute(1, 0, 2)\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "198d4e03-6977-4395-9871-62de67bbb403",
   "metadata": {},
   "outputs": [],
   "source": [
    "crnn = CRNN(num_words, rnn_hidden_size=rnn_hidden_size)\n",
    "crnn = crnn.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1360c4d6-9d38-41e2-95eb-1f0b87980e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_text(text):\n",
    "    \n",
    "    text_batch_targets = [word2idx[c] for c in text.split()][:14]\n",
    "    text_batch_targets = text_batch_targets + [0] * (14 - len(text_batch_targets))\n",
    "    text_batch_targets = torch.LongTensor(text_batch_targets)\n",
    "    \n",
    "    return text_batch_targets.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f43cfa16-65ff-4de6-92f4-61b532317d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_predictions(text_batch_logits):\n",
    "\n",
    "    text_batch_tokens = text_batch_logits.argmax(2) # [T, batch_size]\n",
    "    text_batch_tokens = text_batch_tokens.numpy().T # [batch_size, T]\n",
    "\n",
    "    text_batch_tokens_new = []\n",
    "    for text_tokens in text_batch_tokens:\n",
    "        text = [idx2word[idx] for idx in text_tokens if idx != 0]\n",
    "        text = \" \".join(text)\n",
    "        text_batch_tokens_new.append(text)\n",
    "\n",
    "    return text_batch_tokens_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a5b79863-92d7-44d2-951a-05112ea2ad68",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 25\n",
    "lr = 1e-3\n",
    "clip_norm = 5\n",
    "\n",
    "criterion = nn.CTCLoss(blank=0)\n",
    "optimizer = optim.AdamW(crnn.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "86b9178f-9637-44ee-bf32-48013ecf8840",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(text_batch, text_batch_logits):\n",
    "    \"\"\"\n",
    "    text_batch: list of strings of length equal to batch size\n",
    "    text_batch_logits: Tensor of size([T, batch_size, num_classes])\n",
    "    \"\"\"\n",
    "\n",
    "    text_batch_targets = torch.cat([encode_text(text) for text in text_batch]).to(device)\n",
    "    target_lengths = [int((i > 0).sum()) for i in text_batch_targets]\n",
    "    \n",
    "    loss = criterion(\n",
    "        nn.functional.log_softmax(text_batch_logits, dim=2), \n",
    "        text_batch_targets, \n",
    "        input_lengths=[14]*len(target_lengths), \n",
    "        target_lengths=target_lengths\n",
    "    )\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fa7510e4-63d6-495e-a2ce-7ff41894d467",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4014eb14b6d14011a431d8f36afe4b7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2912 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/324 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:1    Loss:5.139543402677914   WER:0.8137347761000943\n",
      "\n",
      "A room with a single bed made up and a desk with computer stuff on it. -> A next and a it.\n",
      "A horse is standing next to a fence. -> A next in a fence.\n",
      "An intersection by the capital building has lots of stoplights. -> A clock of a building.\n",
      "Baker hunched over applying green frosting to pastries. -> A next in a wall.\n",
      "A stove that has an open capartment at the bottom of the stove.  -> A next on a it.\n",
      "Picture of small bathroom in a corner room -> A bathroom bathroom toilet toilet and sink.\n",
      "there is a large plane in the sky that says one world -> A airplane plane flying in the sky.\n",
      "a man is playing around with a picture of a tie -> A man is front in a room.\n",
      "A truck drives in a street near buildings. -> A bus driving on a street.\n",
      "A sign posted in dirt reads hurst grove street pride. -> A next of a building.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2912 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/324 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:2    Loss:4.651111450222435   WER:0.8041129941414552\n",
      "\n",
      "A room with a single bed made up and a desk with computer stuff on it. -> A bed and a bed.\n",
      "A horse is standing next to a fence. -> A next in a fence.\n",
      "An intersection by the capital building has lots of stoplights. -> A with of a it.\n",
      "Baker hunched over applying green frosting to pastries. -> A cat next in a chair.\n",
      "A stove that has an open capartment at the bottom of the stove.  -> A next on a desk.\n",
      "Picture of small bathroom in a corner room -> A bathroom toilet and bathroom.\n",
      "there is a large plane in the sky that says one world -> A large flying flying in sky.\n",
      "a man is playing around with a picture of a tie -> A man in kitchen in a refrigerator.\n",
      "A truck drives in a street near buildings. -> A bus driving on a street.\n",
      "A sign posted in dirt reads hurst grove street pride. -> A street sign on side on a it.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2912 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/324 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:3    Loss:4.430792784809473   WER:0.7974713079155039\n",
      "\n",
      "A room with a single bed made up and a desk with computer stuff on it. -> A cat next and a room.\n",
      "A horse is standing next to a fence. -> A cow cow in a cow.\n",
      "An intersection by the capital building has lots of stoplights. -> A of on a street.\n",
      "Baker hunched over applying green frosting to pastries. -> A man is top of a kitchen.\n",
      "A stove that has an open capartment at the bottom of the stove.  -> A on sitting on a bench.\n",
      "Picture of small bathroom in a corner room -> A bathroom with toilet in a bathroom\n",
      "there is a large plane in the sky that says one world -> A flying flying in the sky.\n",
      "a man is playing around with a picture of a tie -> A man is front in a kitchen.\n",
      "A truck drives in a street near buildings. -> A on a street.\n",
      "A sign posted in dirt reads hurst grove street pride. -> A sign on side on a pole.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2912 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/324 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:4    Loss:4.246728997735855   WER:0.7943849452032009\n",
      "\n",
      "A room with a single bed made up and a desk with computer stuff on it. -> A cat on bed on a bed.\n",
      "A horse is standing next to a fence. -> A walking on a cows.\n",
      "An intersection by the capital building has lots of stoplights. -> A with a light on street.\n",
      "Baker hunched over applying green frosting to pastries. -> A man is cooking of kitchen.\n",
      "A stove that has an open capartment at the bottom of the stove.  -> A on sitting on a floor.\n",
      "Picture of small bathroom in a corner room -> A with a sink and a toilet.\n",
      "there is a large plane in the sky that says one world -> A flying flying in the sky.\n",
      "a man is playing around with a picture of a tie -> A man in front in a refrigerator.\n",
      "A truck drives in a street near buildings. -> A driving driving on a street.\n",
      "A sign posted in dirt reads hurst grove street pride. -> A sign sign on a side of a it.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2912 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/324 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:5    Loss:4.0935927152379215   WER:0.785068103273023\n",
      "\n",
      "A room with a single bed made up and a desk with computer stuff on it. -> A bedroom bed and a room.\n",
      "A horse is standing next to a fence. -> A standing of a fence.\n",
      "An intersection by the capital building has lots of stoplights. -> A traffic with a pole on a street.\n",
      "Baker hunched over applying green frosting to pastries. -> A man is next of a blender.\n",
      "A stove that has an open capartment at the bottom of the stove.  -> A black sitting on a desk.\n",
      "Picture of small bathroom in a corner room -> A with a toilet and a floor.\n",
      "there is a large plane in the sky that says one world -> A large flying flying in the sky.\n",
      "a man is playing around with a picture of a tie -> A man man a unbuttoning unbuttoning front in a refrigerator.\n",
      "A truck drives in a street near buildings. -> A driving on a street.\n",
      "A sign posted in dirt reads hurst grove street pride. -> A sign on a side \"hurst a grove.\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2912 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/324 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:6    Loss:3.9803281939385795   WER:0.787828734591288\n",
      "\n",
      "A room with a single bed made up and a desk with computer stuff on it. -> A bed next and a room.\n",
      "A horse is standing next to a fence. -> A woman is cow of a cow.\n",
      "An intersection by the capital building has lots of stoplights. -> A traffic with lights on signs.\n",
      "Baker hunched over applying green frosting to pastries. -> A man is pot of a pot\n",
      "A stove that has an open capartment at the bottom of the stove.  -> A black on sitting of a floor.\n",
      "Picture of small bathroom in a corner room -> A bathroom bathroom with sink and shower.\n",
      "there is a large plane in the sky that says one world -> A large flying flying in the sky.\n",
      "a man is playing around with a picture of a tie -> A man in front in a doorway.\n",
      "A truck drives in a street near buildings. -> A ads driving on a buildiing\n",
      "A sign posted in dirt reads hurst grove street pride. -> A sign on side on a grove.\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2912 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/324 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:7    Loss:3.8782883998597018   WER:0.7886580790626329\n",
      "\n",
      "A room with a single bed made up and a desk with computer stuff on it. -> A bed with next and lamps.\n",
      "A horse is standing next to a fence. -> A man walking at a cage\n",
      "An intersection by the capital building has lots of stoplights. -> A on traffic on signal.\n",
      "Baker hunched over applying green frosting to pastries. -> A woman standing cake in food.\n",
      "A stove that has an open capartment at the bottom of the stove.  -> A on sitting of a floor.\n",
      "Picture of small bathroom in a corner room -> A bathroom bathroom with a sink and a sink.\n",
      "there is a large plane in the sky that says one world -> A flying in the sky.\n",
      "a man is playing around with a picture of a tie -> A man in front in a doorway.\n",
      "A truck drives in a street near buildings. -> A truck driving driving of a street.\n",
      "A sign posted in dirt reads hurst grove street pride. -> A sign in side of a pole.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2912 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/324 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:8    Loss:3.8058661027095346   WER:0.7842272080430243\n",
      "\n",
      "A room with a single bed made up and a desk with computer stuff on it. -> A bed next and room.\n",
      "A horse is standing next to a fence. -> A hay in a barn.\n",
      "An intersection by the capital building has lots of stoplights. -> A with street on street.\n",
      "Baker hunched over applying green frosting to pastries. -> A man is a of a refrigerator\n",
      "A stove that has an open capartment at the bottom of the stove.  -> A drawer on luggage on a floor.\n",
      "Picture of small bathroom in a corner room -> A bathroom bathroom with sanitizer, toilet and shower.\n",
      "there is a large plane in the sky that says one world -> A large flying flying in the sky.\n",
      "a man is playing around with a picture of a tie -> A man is a unbuttoning button in a tie.\n",
      "A truck drives in a street near buildings. -> A driving on a street.\n",
      "A sign posted in dirt reads hurst grove street pride. -> A sign in a \"hurst \"hurst a grove.\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2912 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/324 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:9    Loss:3.7450117505291955   WER:0.7835156813099484\n",
      "\n",
      "A room with a single bed made up and a desk with computer stuff on it. -> A bed next and a room.\n",
      "A horse is standing next to a fence. -> A cow cage in a cow.\n",
      "An intersection by the capital building has lots of stoplights. -> A traffic on a lights to a city.\n",
      "Baker hunched over applying green frosting to pastries. -> A man is icing of pastry.\n",
      "A stove that has an open capartment at the bottom of the stove.  -> A on drawer of other.\n",
      "Picture of small bathroom in a corner room -> A bathroom with sanitizer, sanitizer, sink and paper.\n",
      "there is a large plane in the sky that says one world -> A large flying flying in the sky.\n",
      "a man is playing around with a picture of a tie -> A man man unbuttoning unbuttoning button in a shirt.\n",
      "A truck drives in a street near buildings. -> A fire truck on a street.\n",
      "A sign posted in dirt reads hurst grove street pride. -> A sign sign on a side of a building.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2912 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/324 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:10    Loss:3.679654554278982   WER:0.7831737788537951\n",
      "\n",
      "A room with a single bed made up and a desk with computer stuff on it. -> A with next and bed.\n",
      "A horse is standing next to a fence. -> A cow is a cage in a fence.\n",
      "An intersection by the capital building has lots of stoplights. -> A traffic lights a lights of a street.\n",
      "Baker hunched over applying green frosting to pastries. -> A man is icing of cookies.\n",
      "A stove that has an open capartment at the bottom of the stove.  -> A black drawer on the drawer of empty.\n",
      "Picture of small bathroom in a corner room -> A bathroom with a sink and bathtub.\n",
      "there is a large plane in the sky that says one world -> A plane plane flying in the sky.\n",
      "a man is playing around with a picture of a tie -> A man man in in a shirt.\n",
      "A truck drives in a street near buildings. -> A truck truck on a street.\n",
      "A sign posted in dirt reads hurst grove street pride. -> A street sign sign in a side \"hurst a grove.\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2912 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/324 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:11    Loss:3.634379927351228   WER:0.7819147461605278\n",
      "\n",
      "A room with a single bed made up and a desk with computer stuff on it. -> A bed and desk and a it.\n",
      "A horse is standing next to a fence. -> A woman on standing in a barn.\n",
      "An intersection by the capital building has lots of stoplights. -> A with of a city.\n",
      "Baker hunched over applying green frosting to pastries. -> A baker baker pastries in a pastry.\n",
      "A stove that has an open capartment at the bottom of the stove.  -> A black drawer on on a floor.\n",
      "Picture of small bathroom in a corner room -> A with sink and shower.\n",
      "there is a large plane in the sky that says one world -> A large plane flying flying in the sky\n",
      "a man is playing around with a picture of a tie -> A man is unbuttoning unbuttoning button in a shirt.\n",
      "A truck drives in a street near buildings. -> A truck driving on a buildiing\n",
      "A sign posted in dirt reads hurst grove street pride. -> A sign sign sign on a front on a grove.\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2912 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/324 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:12    Loss:3.592877071805375   WER:0.7834602376684101\n",
      "\n",
      "A room with a single bed made up and a desk with computer stuff on it. -> A bed with desk and a room.\n",
      "A horse is standing next to a fence. -> A horse cage in a stall.\n",
      "An intersection by the capital building has lots of stoplights. -> A traffic of traffic lights on lights on street.\n",
      "Baker hunched over applying green frosting to pastries. -> A man is pastries of a cookies.\n",
      "A stove that has an open capartment at the bottom of the stove.  -> A on top on a empty.\n",
      "Picture of small bathroom in a corner room -> A bathroom with a sink and bathtub.\n",
      "there is a large plane in the sky that says one world -> A large flying in the sky.\n",
      "a man is playing around with a picture of a tie -> A man man unbuttoning unbuttoning button in his shirt.\n",
      "A truck drives in a street near buildings. -> A truck of a street.\n",
      "A sign posted in dirt reads hurst grove street pride. -> A sign on a side \"hurst a grove.\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2912 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/324 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:13    Loss:3.5604274495985533   WER:0.7820048420780277\n",
      "\n",
      "A room with a single bed made up and a desk with computer stuff on it. -> A bedroom with next and a desk.\n",
      "A horse is standing next to a fence. -> A woman horse harness in a stable.\n",
      "An intersection by the capital building has lots of stoplights. -> A traffic traffic lights with a lights and city.\n",
      "Baker hunched over applying green frosting to pastries. -> A man is pastries of a cookies.\n",
      "A stove that has an open capartment at the bottom of the stove.  -> A drawer on sitting of a box.\n",
      "Picture of small bathroom in a corner room -> A with sanitizer, sink and shower.\n",
      "there is a large plane in the sky that says one world -> A large flying flying in the sky.\n",
      "a man is playing around with a picture of a tie -> A man man a tie in a shirt.\n",
      "A truck drives in a street near buildings. -> A driving on a traffic.\n",
      "A sign posted in dirt reads hurst grove street pride. -> A sign sign sign \"hurst a grove.\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2912 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/324 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:14    Loss:3.5412568639894975   WER:0.7854492783085993\n",
      "\n",
      "A room with a single bed made up and a desk with computer stuff on it. -> A bedroom bedroom with allow and wall.\n",
      "A horse is standing next to a fence. -> A milked in barn.\n",
      "An intersection by the capital building has lots of stoplights. -> A of lights with of street.\n",
      "Baker hunched over applying green frosting to pastries. -> A man is decorating pastries of a icing.\n",
      "A stove that has an open capartment at the bottom of the stove.  -> A on bottom of a empty.\n",
      "Picture of small bathroom in a corner room -> A bathroom with sink and shower.\n",
      "there is a large plane in the sky that says one world -> A large flying in the sky.\n",
      "a man is playing around with a picture of a tie -> A man man in unbuttoning button of a shirt.\n",
      "A truck drives in a street near buildings. -> A truck truck on a street.\n",
      "A sign posted in dirt reads hurst grove street pride. -> A neighborhood sign reads sign of a grove.\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2912 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/324 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:15    Loss:3.505276676857819   WER:0.7863317562697518\n",
      "\n",
      "A room with a single bed made up and a desk with computer stuff on it. -> A with a allow on a computer.\n",
      "A horse is standing next to a fence. -> A brown brown foot in a barn.\n",
      "An intersection by the capital building has lots of stoplights. -> A on pole on street.\n",
      "Baker hunched over applying green frosting to pastries. -> A man is pastries of a cookies.\n",
      "A stove that has an open capartment at the bottom of the stove.  -> A drawer in the seat of a empty.\n",
      "Picture of small bathroom in a corner room -> A bathroom with sanitizer, toilet toilet and floor.\n",
      "there is a large plane in the sky that says one world -> A flying flying through the sky.\n",
      "a man is playing around with a picture of a tie -> A man man unbuttoning unbuttoning button in a shirt.\n",
      "A truck drives in a street near buildings. -> A truck truck is on street.\n",
      "A sign posted in dirt reads hurst grove street pride. -> Hurst Grove sign in the side \"hurst a grove.\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2912 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/324 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:16    Loss:3.478349033217391   WER:0.7827949139699496\n",
      "\n",
      "A room with a single bed made up and a desk with computer stuff on it. -> A bedroom with next on a computer.\n",
      "A horse is standing next to a fence. -> A cow horse horse in a barn.\n",
      "An intersection by the capital building has lots of stoplights. -> A lights with pole on city.\n",
      "Baker hunched over applying green frosting to pastries. -> A is icing icing icing of a pastry.\n",
      "A stove that has an open capartment at the bottom of the stove.  -> A on top of a empty.\n",
      "Picture of small bathroom in a corner room -> A bathroom with a sink and shower.\n",
      "there is a large plane in the sky that says one world -> A flying in the sky.\n",
      "a man is playing around with a picture of a tie -> A man man tie in a tie.\n",
      "A truck drives in a street near buildings. -> A driving is driving on traffic.\n",
      "A sign posted in dirt reads hurst grove street pride. -> A sign on building \"hurst a grove.\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2912 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c82f33d22c346a8847b514bbeba8434",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/324 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:17    Loss:3.4540345221121993   WER:0.7841602136428321\n",
      "\n",
      "A room with a single bed made up and a desk with computer stuff on it. -> A bedroom with next and wall.\n",
      "A horse is standing next to a fence. -> A man horse cage in a barn.\n",
      "An intersection by the capital building has lots of stoplights. -> A of on city.\n",
      "Baker hunched over applying green frosting to pastries. -> A chef is icing of a pastry.\n",
      "A stove that has an open capartment at the bottom of the stove.  -> A drawer on bottom in the empty.\n",
      "Picture of small bathroom in a corner room -> A bathroom bathroom with a towel and shower.\n",
      "there is a large plane in the sky that says one world -> A large flying flying in the sky.\n",
      "a man is playing around with a picture of a tie -> A man man a a tie in a shirt.\n",
      "A truck drives in a street near buildings. -> A though on a intersection.\n",
      "A sign posted in dirt reads hurst grove street pride. -> A sign in a pole \"hurst houses.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a747e0c7abf438381634bc926fe2a54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2912 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d256ddd780a44eab85a274d78af0211",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/324 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:18    Loss:3.4380204789459685   WER:0.7847377515755235\n",
      "\n",
      "A room with a single bed made up and a desk with computer stuff on it. -> A bedroom cramped desk and a computer.\n",
      "A horse is standing next to a fence. -> A horse horse a cage in a barn.\n",
      "An intersection by the capital building has lots of stoplights. -> A of lights pole a intersection of street.\n",
      "Baker hunched over applying green frosting to pastries. -> A man is icing of a cookies.\n",
      "A stove that has an open capartment at the bottom of the stove.  -> A stove drawer on a bottom of a empty.\n",
      "Picture of small bathroom in a corner room -> A bathroom bathroom with a sink and shower.\n",
      "there is a large plane in the sky that says one world -> A flying flying in the sky.\n",
      "a man is playing around with a picture of a tie -> A man unbuttoning unbuttoning unbuttoning button in a shirt.\n",
      "A truck drives in a street near buildings. -> A truck truck on a street.\n",
      "A sign posted in dirt reads hurst grove street pride. -> Hurst Grove sign in a sign of a building.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66a553df12734698964ce70cc3203b91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2912 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "501334db4f754ef290cf0507ca7a77a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/324 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:19    Loss:3.415228024522393   WER:0.7845852815612929\n",
      "\n",
      "A room with a single bed made up and a desk with computer stuff on it. -> A cat and on a allow on a room.\n",
      "A horse is standing next to a fence. -> A cow cow cage in a stall.\n",
      "An intersection by the capital building has lots of stoplights. -> A of lights with intersection on street.\n",
      "Baker hunched over applying green frosting to pastries. -> A man is table of a icing.\n",
      "A stove that has an open capartment at the bottom of the stove.  -> A drawer on drawer of a empty.\n",
      "Picture of small bathroom in a corner room -> A bathroom bathroom with sanitizer, sink and shower.\n",
      "there is a large plane in the sky that says one world -> A airplane plane flying flying in the sky\n",
      "a man is playing around with a picture of a tie -> A standing in a front of his tie.\n",
      "A truck drives in a street near buildings. -> A red truck driving on parked on a buildiing\n",
      "A sign posted in dirt reads hurst grove street pride. -> A Grove sign entrance of a houses.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2912 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/324 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:20    Loss:3.396272819376754   WER:0.7861746659520598\n",
      "\n",
      "A room with a single bed made up and a desk with computer stuff on it. -> A bed on allow on a room.\n",
      "A horse is standing next to a fence. -> A cow horse walking in a barn.\n",
      "An intersection by the capital building has lots of stoplights. -> A of lights on intersection on street.\n",
      "Baker hunched over applying green frosting to pastries. -> A person is icing of a pastry.\n",
      "A stove that has an open capartment at the bottom of the stove.  -> A of window.\n",
      "Picture of small bathroom in a corner room -> A bathroom bathroom with a sink and shower.\n",
      "there is a large plane in the sky that says one world -> A airplane flying in the sky.\n",
      "a man is playing around with a picture of a tie -> A man man unbuttoning unbuttoning button of a shirt.\n",
      "A truck drives in a street near buildings. -> A red on a buildiing\n",
      "A sign posted in dirt reads hurst grove street pride. -> Hurst Grove sign community to street.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2912 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/324 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:21    Loss:3.3789788580771405   WER:0.786428782642444\n",
      "\n",
      "A room with a single bed made up and a desk with computer stuff on it. -> A bed next on a wall.\n",
      "A horse is standing next to a fence. -> A brown horse stable in a barn.\n",
      "An intersection by the capital building has lots of stoplights. -> A of lights with walk of light.\n",
      "Baker hunched over applying green frosting to pastries. -> A man is pastries of a pastry.\n",
      "A stove that has an open capartment at the bottom of the stove.  -> A drawer in top of a empty.\n",
      "Picture of small bathroom in a corner room -> A bathroom with handicap accessible accented and brown.\n",
      "there is a large plane in the sky that says one world -> A large plane plane through the sky.\n",
      "a man is playing around with a picture of a tie -> A man with a a in a neck.\n",
      "A truck drives in a street near buildings. -> A truck truck bus on a street.\n",
      "A sign posted in dirt reads hurst grove street pride. -> A neighborhood to it.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2912 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/324 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:22    Loss:3.380257229342225   WER:0.7876808848805189\n",
      "\n",
      "A room with a single bed made up and a desk with computer stuff on it. -> A bed with a allow and minimal room.\n",
      "A horse is standing next to a fence. -> A brown horse hay in a barn.\n",
      "An intersection by the capital building has lots of stoplights. -> A lights intersection of a road.\n",
      "Baker hunched over applying green frosting to pastries. -> A man is pastries of a pastry.\n",
      "A stove that has an open capartment at the bottom of the stove.  -> A oven drawer drawer of a empty.\n",
      "Picture of small bathroom in a corner room -> A bathroom with sink and sink\n",
      "there is a large plane in the sky that says one world -> A plane plane in the sky\n",
      "a man is playing around with a picture of a tie -> A man holding in tie of a tie.\n",
      "A truck drives in a street near buildings. -> A truck of a street.\n",
      "A sign posted in dirt reads hurst grove street pride. -> Hurst Grove sign community in of building.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2912 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/324 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:23    Loss:3.361677549013418   WER:0.7842341384982165\n",
      "\n",
      "A room with a single bed made up and a desk with computer stuff on it. -> A allow and minimal room.\n",
      "A horse is standing next to a fence. -> A brown a horse in a barn.\n",
      "An intersection by the capital building has lots of stoplights. -> A of lights with all of a street.\n",
      "Baker hunched over applying green frosting to pastries. -> A baker baker icing of a icing.\n",
      "A stove that has an open capartment at the bottom of the stove.  -> A utility drawer drawer of empty.\n",
      "Picture of small bathroom in a corner room -> A bathroom with a sink and shower.\n",
      "there is a large plane in the sky that says one world -> A large plane flying flying through the sky.\n",
      "a man is playing around with a picture of a tie -> A man man wearing button in a tie\n",
      "A truck drives in a street near buildings. -> A driving of street.\n",
      "A sign posted in dirt reads hurst grove street pride. -> A in entrance to a sign.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2912 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/324 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:24    Loss:3.3607217902519744   WER:0.7897461605278234\n",
      "\n",
      "A room with a single bed made up and a desk with computer stuff on it. -> A bedroom with next on a computer.\n",
      "A horse is standing next to a fence. -> A brown horse standing in a barn.\n",
      "An intersection by the capital building has lots of stoplights. -> A traffic lights with lights of city.\n",
      "Baker hunched over applying green frosting to pastries. -> A baker is pastries of a icing.\n",
      "A stove that has an open capartment at the bottom of the stove.  -> A oven bottom of a empty.\n",
      "Picture of small bathroom in a corner room -> A sink with sink and sink.\n",
      "there is a large plane in the sky that says one world -> A large flying through the sky\n",
      "a man is playing around with a picture of a tie -> A man man in a tie of a neck.\n",
      "A truck drives in a street near buildings. -> A truck driving though driving on traffic.\n",
      "A sign posted in dirt reads hurst grove street pride. -> Hurst sign on a to houses.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2912 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/324 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:25    Loss:3.3529478908008774   WER:0.7856456412057143\n",
      "\n",
      "A room with a single bed made up and a desk with computer stuff on it. -> A bed next and a computer.\n",
      "A horse is standing next to a fence. -> A black and harness in a barn\n",
      "An intersection by the capital building has lots of stoplights. -> A traffic traffic traffic lights of lights of street.\n",
      "Baker hunched over applying green frosting to pastries. -> A baker baker decorating pastries of a icing.\n",
      "A stove that has an open capartment at the bottom of the stove.  -> A drawer on a drawer of a appliance.\n",
      "Picture of small bathroom in a corner room -> A bathroom with tub/shower sink and sink.\n",
      "there is a large plane in the sky that says one world -> A in the sky\n",
      "a man is playing around with a picture of a tie -> A man man a a standing of his tie.\n",
      "A truck drives in a street near buildings. -> A truck driving driving on a street.\n",
      "A sign posted in dirt reads hurst grove street pride. -> A telephone sign is a sign of a it.\n"
     ]
    }
   ],
   "source": [
    "scaler = torch.cuda.amp.GradScaler(enabled = True)\n",
    "\n",
    "epoch_losses = []\n",
    "iteration_losses = []\n",
    "num_updates_epochs = []\n",
    "for epoch in tqdm(range(1, num_epochs+1)):\n",
    "    \n",
    "    crnn.train()\n",
    "    \n",
    "    epoch_loss_list = [] \n",
    "    num_updates_epoch = 0\n",
    "    for image_batch, text_batch in tqdm(train_loader, leave=False):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        with torch.cuda.amp.autocast(enabled = True):\n",
    "            text_batch_logits = crnn(image_batch.to(device))\n",
    "            loss = compute_loss(text_batch, text_batch_logits)\n",
    "            \n",
    "        iteration_loss = loss.item()\n",
    "        \n",
    "        if iteration_loss == float('inf'):\n",
    "            continue\n",
    "          \n",
    "        epoch_loss_list.append(iteration_loss)\n",
    "        \n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.unscale_(optimizer)\n",
    "        torch.nn.utils.clip_grad_norm_(crnn.parameters(), clip_norm)\n",
    "        scaler.step(optimizer)\n",
    "\n",
    "        scaler.update()\n",
    "\n",
    "    crnn.eval()\n",
    "    \n",
    "    pred_str = []\n",
    "    label_str = []\n",
    "    for image_batch, text_batch in tqdm(test_loader, leave=False):\n",
    "        with torch.cuda.amp.autocast(enabled = True):\n",
    "            text_batch_logits = crnn(image_batch.to(device))\n",
    "            \n",
    "        pred_text_batch = decode_predictions(text_batch_logits.cpu())\n",
    "        \n",
    "        pred_str += pred_text_batch\n",
    "        label_str += text_batch\n",
    "        \n",
    "    epoch_loss = np.mean(epoch_loss_list)\n",
    "    wer = wer_metric.compute(predictions=pred_str, references=label_str)\n",
    "    print()\n",
    "    print(f\"Epoch:{epoch}    Loss:{epoch_loss}   WER:{wer}\")\n",
    "    print()\n",
    "    for p, l in zip(pred_str[:10], label_str[:10]):\n",
    "        print(l, '->', p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26ef3a9-62ef-4f08-881a-76c7b8bff9f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
