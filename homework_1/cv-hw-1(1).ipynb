{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Setup","metadata":{}},{"cell_type":"code","source":"!pip install torch\n!pip install torchvision\n!pip install numpy\n!pip install pandas\n!pip install thop\n!pip install tqdm\n!pip install fiftyone\n!pip install opencv-python\n!pip install matplotlib\n!pip install pillow","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-26T17:55:29.420674Z","iopub.execute_input":"2024-04-26T17:55:29.421084Z","iopub.status.idle":"2024-04-26T17:58:30.788327Z","shell.execute_reply.started":"2024-04-26T17:55:29.421053Z","shell.execute_reply":"2024-04-26T17:58:30.787117Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.1.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.2.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (0.16.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision) (1.26.4)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision) (2.31.0)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from torchvision) (2.1.2)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision) (9.5.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (2024.2.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->torchvision) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->torchvision) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->torchvision) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->torchvision) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->torchvision) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->torchvision) (2024.2.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->torchvision) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->torchvision) (1.3.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (1.26.4)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (2.1.4)\nRequirement already satisfied: numpy<2,>=1.22.4 in /opt/conda/lib/python3.10/site-packages (from pandas) (1.26.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2023.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\nCollecting thop\n  Downloading thop-0.1.1.post2209072238-py3-none-any.whl.metadata (2.7 kB)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from thop) (2.1.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->thop) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->thop) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->thop) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->thop) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->thop) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->thop) (2024.2.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->thop) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->thop) (1.3.0)\nDownloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\nInstalling collected packages: thop\nSuccessfully installed thop-0.1.1.post2209072238\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (4.66.1)\nCollecting fiftyone\n  Downloading fiftyone-0.23.8-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: aiofiles in /opt/conda/lib/python3.10/site-packages (from fiftyone) (22.1.0)\nCollecting argcomplete (from fiftyone)\n  Downloading argcomplete-3.3.0-py3-none-any.whl.metadata (16 kB)\nRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from fiftyone) (4.12.2)\nRequirement already satisfied: boto3 in /opt/conda/lib/python3.10/site-packages (from fiftyone) (1.26.100)\nRequirement already satisfied: cachetools in /opt/conda/lib/python3.10/site-packages (from fiftyone) (4.2.4)\nCollecting dacite<1.8.0,>=1.6.0 (from fiftyone)\n  Downloading dacite-1.7.0-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: Deprecated in /opt/conda/lib/python3.10/site-packages (from fiftyone) (1.2.14)\nCollecting ftfy (from fiftyone)\n  Downloading ftfy-6.2.0-py3-none-any.whl.metadata (7.3 kB)\nCollecting humanize (from fiftyone)\n  Downloading humanize-4.9.0-py3-none-any.whl.metadata (7.9 kB)\nCollecting hypercorn>=0.13.2 (from fiftyone)\n  Downloading hypercorn-0.16.0-py3-none-any.whl.metadata (5.4 kB)\nRequirement already satisfied: Jinja2>=3 in /opt/conda/lib/python3.10/site-packages (from fiftyone) (3.1.2)\nCollecting kaleido!=0.2.1.post1 (from fiftyone)\n  Downloading kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl.metadata (15 kB)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from fiftyone) (3.7.5)\nCollecting mongoengine==0.24.2 (from fiftyone)\n  Downloading mongoengine-0.24.2-py3-none-any.whl.metadata (6.7 kB)\nCollecting motor>=2.5 (from fiftyone)\n  Downloading motor-3.4.0-py3-none-any.whl.metadata (21 kB)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from fiftyone) (1.26.4)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from fiftyone) (21.3)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from fiftyone) (2.1.4)\nRequirement already satisfied: Pillow>=6.2 in /opt/conda/lib/python3.10/site-packages (from fiftyone) (9.5.0)\nRequirement already satisfied: plotly>=4.14 in /opt/conda/lib/python3.10/site-packages (from fiftyone) (5.18.0)\nCollecting pprintpp (from fiftyone)\n  Downloading pprintpp-0.4.0-py2.py3-none-any.whl.metadata (7.9 kB)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from fiftyone) (5.9.3)\nRequirement already satisfied: pymongo>=3.12 in /opt/conda/lib/python3.10/site-packages (from fiftyone) (3.13.0)\nRequirement already satisfied: pytz in /opt/conda/lib/python3.10/site-packages (from fiftyone) (2023.3.post1)\nRequirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from fiftyone) (6.0.1)\nRequirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from fiftyone) (2023.12.25)\nRequirement already satisfied: retrying in /opt/conda/lib/python3.10/site-packages (from fiftyone) (1.3.3)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from fiftyone) (1.2.2)\nRequirement already satisfied: scikit-image in /opt/conda/lib/python3.10/site-packages (from fiftyone) (0.22.0)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from fiftyone) (1.11.4)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from fiftyone) (69.0.3)\nCollecting sseclient-py<2,>=1.7.2 (from fiftyone)\n  Downloading sseclient_py-1.8.0-py2.py3-none-any.whl.metadata (2.0 kB)\nCollecting sse-starlette<1,>=0.10.3 (from fiftyone)\n  Downloading sse_starlette-0.10.3-py3-none-any.whl.metadata (4.3 kB)\nRequirement already satisfied: starlette>=0.24.0 in /opt/conda/lib/python3.10/site-packages (from fiftyone) (0.32.0.post1)\nCollecting strawberry-graphql==0.138.1 (from fiftyone)\n  Downloading strawberry_graphql-0.138.1-py3-none-any.whl.metadata (7.0 kB)\nRequirement already satisfied: tabulate in /opt/conda/lib/python3.10/site-packages (from fiftyone) (0.9.0)\nCollecting xmltodict (from fiftyone)\n  Downloading xmltodict-0.13.0-py2.py3-none-any.whl.metadata (7.7 kB)\nCollecting universal-analytics-python3<2,>=1.0.1 (from fiftyone)\n  Downloading universal_analytics_python3-1.1.1-py3-none-any.whl.metadata (5.5 kB)\nCollecting fiftyone-brain<0.17,>=0.16.1 (from fiftyone)\n  Downloading fiftyone_brain-0.16.1-py3-none-any.whl.metadata (12 kB)\nCollecting fiftyone-db<2.0,>=0.4 (from fiftyone)\n  Downloading fiftyone_db-1.1.2.tar.gz (7.9 kB)\n  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hCollecting voxel51-eta<0.13,>=0.12.6 (from fiftyone)\n  Downloading voxel51_eta-0.12.6-py2.py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: opencv-python-headless in /opt/conda/lib/python3.10/site-packages (from fiftyone) (4.9.0.80)\nCollecting graphql-core<3.3.0,>=3.2.0 (from strawberry-graphql==0.138.1->fiftyone)\n  Downloading graphql_core-3.2.3-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: python-dateutil<3.0.0,>=2.7.0 in /opt/conda/lib/python3.10/site-packages (from strawberry-graphql==0.138.1->fiftyone) (2.9.0.post0)\nRequirement already satisfied: typing_extensions<5.0.0,>=3.7.4 in /opt/conda/lib/python3.10/site-packages (from strawberry-graphql==0.138.1->fiftyone) (4.9.0)\nRequirement already satisfied: h11 in /opt/conda/lib/python3.10/site-packages (from hypercorn>=0.13.2->fiftyone) (0.14.0)\nCollecting h2>=3.1.0 (from hypercorn>=0.13.2->fiftyone)\n  Downloading h2-4.1.0-py3-none-any.whl.metadata (3.6 kB)\nCollecting priority (from hypercorn>=0.13.2->fiftyone)\n  Downloading priority-2.0.0-py3-none-any.whl.metadata (6.6 kB)\nCollecting taskgroup (from hypercorn>=0.13.2->fiftyone)\n  Downloading taskgroup-0.0.0a4-py2.py3-none-any.whl.metadata (327 bytes)\nRequirement already satisfied: tomli in /opt/conda/lib/python3.10/site-packages (from hypercorn>=0.13.2->fiftyone) (2.0.1)\nCollecting wsproto>=0.14.0 (from hypercorn>=0.13.2->fiftyone)\n  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from Jinja2>=3->fiftyone) (2.1.3)\nCollecting pymongo>=3.12 (from fiftyone)\n  Downloading pymongo-4.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\nRequirement already satisfied: tenacity>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from plotly>=4.14->fiftyone) (8.2.3)\nCollecting dnspython<3.0.0,>=1.16.0 (from pymongo>=3.12->fiftyone)\n  Downloading dnspython-2.6.1-py3-none-any.whl.metadata (5.8 kB)\nRequirement already satisfied: anyio<5,>=3.4.0 in /opt/conda/lib/python3.10/site-packages (from starlette>=0.24.0->fiftyone) (4.2.0)\nRequirement already satisfied: httpx>=0.10.0 in /opt/conda/lib/python3.10/site-packages (from universal-analytics-python3<2,>=1.0.1->fiftyone) (0.27.0)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from voxel51-eta<0.13,>=0.12.6->fiftyone) (0.3.8)\nRequirement already satisfied: future in /opt/conda/lib/python3.10/site-packages (from voxel51-eta<0.13,>=0.12.6->fiftyone) (1.0.0)\nCollecting glob2 (from voxel51-eta<0.13,>=0.12.6->fiftyone)\n  Downloading glob2-0.7.tar.gz (10 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting jsonlines (from voxel51-eta<0.13,>=0.12.6->fiftyone)\n  Downloading jsonlines-4.0.0-py3-none-any.whl.metadata (1.6 kB)\nCollecting py7zr (from voxel51-eta<0.13,>=0.12.6->fiftyone)\n  Downloading py7zr-0.21.0-py3-none-any.whl.metadata (17 kB)\nCollecting rarfile (from voxel51-eta<0.13,>=0.12.6->fiftyone)\n  Downloading rarfile-4.2-py3-none-any.whl.metadata (4.4 kB)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from voxel51-eta<0.13,>=0.12.6->fiftyone) (2.31.0)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from voxel51-eta<0.13,>=0.12.6->fiftyone) (1.16.0)\nRequirement already satisfied: sortedcontainers in /opt/conda/lib/python3.10/site-packages (from voxel51-eta<0.13,>=0.12.6->fiftyone) (2.4.0)\nCollecting tzlocal (from voxel51-eta<0.13,>=0.12.6->fiftyone)\n  Downloading tzlocal-5.2-py3-none-any.whl.metadata (7.8 kB)\nRequirement already satisfied: urllib3 in /opt/conda/lib/python3.10/site-packages (from voxel51-eta<0.13,>=0.12.6->fiftyone) (1.26.18)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->fiftyone) (2.5)\nCollecting botocore<1.30.0,>=1.29.100 (from boto3->fiftyone)\n  Downloading botocore-1.29.165-py3-none-any.whl.metadata (5.9 kB)\nRequirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from boto3->fiftyone) (1.0.1)\nRequirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from boto3->fiftyone) (0.6.2)\nRequirement already satisfied: wrapt<2,>=1.10 in /opt/conda/lib/python3.10/site-packages (from Deprecated->fiftyone) (1.14.1)\nRequirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /opt/conda/lib/python3.10/site-packages (from ftfy->fiftyone) (0.2.13)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->fiftyone) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->fiftyone) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->fiftyone) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->fiftyone) (1.4.5)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->fiftyone) (3.1.1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->fiftyone) (2023.4)\nRequirement already satisfied: networkx>=2.8 in /opt/conda/lib/python3.10/site-packages (from scikit-image->fiftyone) (3.2.1)\nRequirement already satisfied: imageio>=2.27 in /opt/conda/lib/python3.10/site-packages (from scikit-image->fiftyone) (2.33.1)\nRequirement already satisfied: tifffile>=2022.8.12 in /opt/conda/lib/python3.10/site-packages (from scikit-image->fiftyone) (2023.12.9)\nRequirement already satisfied: lazy_loader>=0.3 in /opt/conda/lib/python3.10/site-packages (from scikit-image->fiftyone) (0.3)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->fiftyone) (1.4.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->fiftyone) (3.2.0)\nRequirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette>=0.24.0->fiftyone) (3.6)\nRequirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette>=0.24.0->fiftyone) (1.3.0)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette>=0.24.0->fiftyone) (1.2.0)\nCollecting hyperframe<7,>=6.0 (from h2>=3.1.0->hypercorn>=0.13.2->fiftyone)\n  Downloading hyperframe-6.0.1-py3-none-any.whl.metadata (2.7 kB)\nCollecting hpack<5,>=4.0 (from h2>=3.1.0->hypercorn>=0.13.2->fiftyone)\n  Downloading hpack-4.0.0-py3-none-any.whl.metadata (2.5 kB)\nRequirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx>=0.10.0->universal-analytics-python3<2,>=1.0.1->fiftyone) (2024.2.2)\nRequirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx>=0.10.0->universal-analytics-python3<2,>=1.0.1->fiftyone) (1.0.5)\nRequirement already satisfied: attrs>=19.2.0 in /opt/conda/lib/python3.10/site-packages (from jsonlines->voxel51-eta<0.13,>=0.12.6->fiftyone) (23.2.0)\nRequirement already satisfied: texttable in /opt/conda/lib/python3.10/site-packages (from py7zr->voxel51-eta<0.13,>=0.12.6->fiftyone) (1.7.0)\nCollecting pycryptodomex>=3.16.0 (from py7zr->voxel51-eta<0.13,>=0.12.6->fiftyone)\n  Downloading pycryptodomex-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\nCollecting pyzstd>=0.15.9 (from py7zr->voxel51-eta<0.13,>=0.12.6->fiftyone)\n  Downloading pyzstd-0.15.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.9 kB)\nCollecting pyppmd<1.2.0,>=1.1.0 (from py7zr->voxel51-eta<0.13,>=0.12.6->fiftyone)\n  Downloading pyppmd-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.7 kB)\nCollecting pybcj<1.1.0,>=1.0.0 (from py7zr->voxel51-eta<0.13,>=0.12.6->fiftyone)\n  Downloading pybcj-1.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\nCollecting multivolumefile>=0.2.3 (from py7zr->voxel51-eta<0.13,>=0.12.6->fiftyone)\n  Downloading multivolumefile-0.2.3-py3-none-any.whl.metadata (6.3 kB)\nCollecting inflate64<1.1.0,>=1.0.0 (from py7zr->voxel51-eta<0.13,>=0.12.6->fiftyone)\n  Downloading inflate64-1.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\nCollecting brotli>=1.1.0 (from py7zr->voxel51-eta<0.13,>=0.12.6->fiftyone)\n  Downloading Brotli-1.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.5 kB)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->voxel51-eta<0.13,>=0.12.6->fiftyone) (3.3.2)\nDownloading fiftyone-0.23.8-py3-none-any.whl (7.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m56.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading mongoengine-0.24.2-py3-none-any.whl (108 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.9/108.9 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading strawberry_graphql-0.138.1-py3-none-any.whl (192 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m192.5/192.5 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading dacite-1.7.0-py3-none-any.whl (12 kB)\nDownloading fiftyone_brain-0.16.1-py3-none-any.whl (89 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.6/89.6 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading hypercorn-0.16.0-py3-none-any.whl (59 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.9/59.9 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl (79.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.9/79.9 MB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading motor-3.4.0-py3-none-any.whl (74 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.3/74.3 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pymongo-4.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (670 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.1/670.1 kB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading sse_starlette-0.10.3-py3-none-any.whl (8.0 kB)\nDownloading sseclient_py-1.8.0-py2.py3-none-any.whl (8.8 kB)\nDownloading universal_analytics_python3-1.1.1-py3-none-any.whl (10 kB)\nDownloading voxel51_eta-0.12.6-py2.py3-none-any.whl (942 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m942.9/942.9 kB\u001b[0m \u001b[31m46.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading argcomplete-3.3.0-py3-none-any.whl (42 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading ftfy-6.2.0-py3-none-any.whl (54 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.4/54.4 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading humanize-4.9.0-py3-none-any.whl (126 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.8/126.8 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pprintpp-0.4.0-py2.py3-none-any.whl (16 kB)\nDownloading xmltodict-0.13.0-py2.py3-none-any.whl (10.0 kB)\nDownloading botocore-1.29.165-py3-none-any.whl (11.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.0/11.0 MB\u001b[0m \u001b[31m104.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading graphql_core-3.2.3-py3-none-any.whl (202 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m202.9/202.9 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading h2-4.1.0-py3-none-any.whl (57 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading wsproto-1.2.0-py3-none-any.whl (24 kB)\nDownloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\nDownloading priority-2.0.0-py3-none-any.whl (8.9 kB)\nDownloading py7zr-0.21.0-py3-none-any.whl (67 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading rarfile-4.2-py3-none-any.whl (29 kB)\nDownloading taskgroup-0.0.0a4-py2.py3-none-any.whl (9.1 kB)\nDownloading tzlocal-5.2-py3-none-any.whl (17 kB)\nDownloading Brotli-1.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading hpack-4.0.0-py3-none-any.whl (32 kB)\nDownloading hyperframe-6.0.1-py3-none-any.whl (12 kB)\nDownloading inflate64-1.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (93 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading multivolumefile-0.2.3-py3-none-any.whl (17 kB)\nDownloading pybcj-1.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.7/49.7 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pycryptodomex-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m45.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading pyppmd-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.9/138.9 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pyzstd-0.15.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (411 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m411.2/411.2 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: fiftyone-db, glob2\n  Building wheel for fiftyone-db (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for fiftyone-db: filename=fiftyone_db-1.1.2-py3-none-manylinux1_x86_64.whl size=37851557 sha256=25e08c90c0d297da62b7162d9594c22ccd1d62e74f0cb7fd20c3f7ff80b808d4\n  Stored in directory: /root/.cache/pip/wheels/29/52/b9/14b9d344410c63c0447ba16bf47c0a064c55d735fa14ecf95c\n  Building wheel for glob2 (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for glob2: filename=glob2-0.7-py2.py3-none-any.whl size=9300 sha256=323fc22adca7660b9fbcd9072099d7128e79f43c4c580d5f9640af46f12838a5\n  Stored in directory: /root/.cache/pip/wheels/37/07/ce/cbe8d31ad93224571b49fa03f8a5da11cdb31d3845ff73e0f3\nSuccessfully built fiftyone-db glob2\nInstalling collected packages: sseclient-py, pprintpp, kaleido, glob2, brotli, xmltodict, wsproto, tzlocal, taskgroup, rarfile, pyzstd, pyppmd, pycryptodomex, pybcj, priority, multivolumefile, jsonlines, inflate64, hyperframe, humanize, hpack, graphql-core, ftfy, fiftyone-db, dnspython, dacite, argcomplete, strawberry-graphql, pymongo, py7zr, h2, botocore, voxel51-eta, universal-analytics-python3, sse-starlette, motor, mongoengine, hypercorn, fiftyone-brain, fiftyone\n  Attempting uninstall: brotli\n    Found existing installation: Brotli 1.0.9\n    Uninstalling Brotli-1.0.9:\n      Successfully uninstalled Brotli-1.0.9\n  Attempting uninstall: dacite\n    Found existing installation: dacite 1.8.1\n    Uninstalling dacite-1.8.1:\n      Successfully uninstalled dacite-1.8.1\n  Attempting uninstall: pymongo\n    Found existing installation: pymongo 3.13.0\n    Uninstalling pymongo-3.13.0:\n      Successfully uninstalled pymongo-3.13.0\n  Attempting uninstall: botocore\n    Found existing installation: botocore 1.34.69\n    Uninstalling botocore-1.34.69:\n      Successfully uninstalled botocore-1.34.69\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\naiobotocore 2.12.3 requires botocore<1.34.70,>=1.34.41, but you have botocore 1.29.165 which is incompatible.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\napache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 15.0.2 which is incompatible.\napache-beam 2.46.0 requires pymongo<4.0.0,>=3.8.0, but you have pymongo 4.7.0 which is incompatible.\nydata-profiling 4.6.4 requires dacite>=1.8, but you have dacite 1.7.0 which is incompatible.\nydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed argcomplete-3.3.0 botocore-1.29.165 brotli-1.1.0 dacite-1.7.0 dnspython-2.6.1 fiftyone-0.23.8 fiftyone-brain-0.16.1 fiftyone-db-1.1.2 ftfy-6.2.0 glob2-0.7 graphql-core-3.2.3 h2-4.1.0 hpack-4.0.0 humanize-4.9.0 hypercorn-0.16.0 hyperframe-6.0.1 inflate64-1.0.0 jsonlines-4.0.0 kaleido-0.2.1 mongoengine-0.24.2 motor-3.4.0 multivolumefile-0.2.3 pprintpp-0.4.0 priority-2.0.0 py7zr-0.21.0 pybcj-1.0.2 pycryptodomex-3.20.0 pymongo-4.7.0 pyppmd-1.1.0 pyzstd-0.15.10 rarfile-4.2 sse-starlette-0.10.3 sseclient-py-1.8.0 strawberry-graphql-0.138.1 taskgroup-0.0.0a4 tzlocal-5.2 universal-analytics-python3-1.1.1 voxel51-eta-0.12.6 wsproto-1.2.0 xmltodict-0.13.0\nRequirement already satisfied: opencv-python in /opt/conda/lib/python3.10/site-packages (4.9.0.80)\nRequirement already satisfied: numpy>=1.21.2 in /opt/conda/lib/python3.10/site-packages (from opencv-python) (1.26.4)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (3.7.5)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.4.5)\nRequirement already satisfied: numpy<2,>=1.20 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (21.3)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (9.5.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (3.1.1)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (2.9.0.post0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\nRequirement already satisfied: pillow in /opt/conda/lib/python3.10/site-packages (9.5.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport sys\nimport time\nimport numpy as np\nfrom PIL import Image\nimport torch\nimport torch.nn as nn\nimport torch.nn.init as init\nimport torchvision\nimport fiftyone as fo\nimport fiftyone.zoo as foz\nimport fiftyone.utils.coco as fouc\nfrom tqdm import tqdm\nfrom PIL import Image\nfrom itertools import product","metadata":{"execution":{"iopub.status.busy":"2024-04-26T17:58:30.790489Z","iopub.execute_input":"2024-04-26T17:58:30.790822Z","iopub.status.idle":"2024-04-26T17:58:38.623087Z","shell.execute_reply.started":"2024-04-26T17:58:30.790792Z","shell.execute_reply":"2024-04-26T17:58:38.622018Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Migrating database to v0.23.8\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Data","metadata":{}},{"cell_type":"code","source":"class FiftyOneTorchDataset(torch.utils.data.Dataset):\n    \"\"\"A class to construct a PyTorch dataset from a FiftyOne dataset.\n\n    Args:\n        fiftyone_dataset: a FiftyOne dataset or view that will be used for training or testing\n        transforms (None): a list of PyTorch transforms to apply to images and targets when loading\n        gt_field (\"ground_truth\"): the name of the field in fiftyone_dataset that contains the\n            desired labels to load\n        classes (None): a list of class strings that are used to define the mapping between\n            class names and indices. If None, it will use all classes present in the given fiftyone_dataset.\n    \"\"\"\n\n    def __init__(\n        self,\n        fiftyone_dataset,\n        transforms=None,\n        gt_field=\"ground_truth\",\n        classes=None,\n    ):\n        self.samples = fiftyone_dataset\n        self.transforms = transforms\n        self.gt_field = gt_field\n\n        self.img_paths = self.samples.values(\"filepath\")\n\n        self.classes = classes\n        if not self.classes:\n            # Get list of distinct labels that exist in the view\n            self.classes = self.samples.distinct(\n                \"%s.detections.label\" % gt_field\n            )\n\n        if self.classes[0] != \"background\":\n            self.classes = [\"background\"] + self.classes\n\n        self.labels_map_rev = {c: i for i, c in enumerate(self.classes)}\n\n    def __getitem__(self, idx):\n        img_path = self.img_paths[idx]\n        sample = self.samples[img_path]\n        metadata = sample.metadata\n        img = Image.open(img_path).convert(\"RGB\")\n        width, height = img.size\n\n        boxes = []\n        labels = []\n        area = []\n        iscrowd = []\n        if sample[self.gt_field] is not None:\n            detections = sample[self.gt_field].detections\n            for det in detections:\n                category_id = self.labels_map_rev[det.label]\n                coco_obj = fouc.COCOObject.from_label(\n                    det, metadata, category_id=category_id,\n                )\n                x, y, w, h = coco_obj.bbox\n                boxes.append([(x + w / 2) / width, (y + h / 2) / height, w / width, h / height]) # normalized (xc, yc, w, h)\n                labels.append(coco_obj.category_id)\n                area.append(coco_obj.area)\n                iscrowd.append(coco_obj.iscrowd)\n\n        target = {}\n        target[\"boxes\"] = torch.as_tensor(boxes, dtype=torch.float32)\n        target[\"labels\"] = torch.as_tensor(labels, dtype=torch.int64)\n        target[\"image_id\"] = torch.as_tensor([idx])\n        target[\"area\"] = torch.as_tensor(area, dtype=torch.float32)\n        target[\"iscrowd\"] = torch.as_tensor(iscrowd, dtype=torch.int64)\n\n        if self.transforms is not None:\n            img, target = self.transforms(img, target)\n\n        return img, target\n\n    def __len__(self):\n        return len(self.img_paths)\n\n    def get_classes(self):\n        return self.classes","metadata":{"execution":{"iopub.status.busy":"2024-04-26T17:58:38.624561Z","iopub.execute_input":"2024-04-26T17:58:38.624932Z","iopub.status.idle":"2024-04-26T17:58:38.639553Z","shell.execute_reply.started":"2024-04-26T17:58:38.624906Z","shell.execute_reply":"2024-04-26T17:58:38.638769Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"class Transformtsz:\n    def __init__(self, resize):\n        self.resize = resize\n    def __call__(self, image, boxes):\n        image = torchvision.transforms.functional.resize(image, self.resize)\n        image = torchvision.transforms.functional.to_tensor(image)\n        return image, boxes","metadata":{"execution":{"iopub.status.busy":"2024-04-26T17:58:38.641602Z","iopub.execute_input":"2024-04-26T17:58:38.641877Z","iopub.status.idle":"2024-04-26T17:58:38.653232Z","shell.execute_reply.started":"2024-04-26T17:58:38.641855Z","shell.execute_reply":"2024-04-26T17:58:38.652355Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def collate(batch, grid_size=7, n_classes=80):\n    images = []\n    gt = []\n    for item in batch:\n        images.append(item[0].unsqueeze(0))\n\n        fmap = torch.zeros(1, grid_size, grid_size, 5*2+n_classes)\n        bboxes = item[1][\"boxes\"]\n        labels = item[1][\"labels\"]\n\n        used_col_row = {(r, c): 0 for r,c in list(product(range(7), repeat=2))}\n        for bbox, label in zip(bboxes, labels):\n            col = int(bbox[1] * grid_size)\n            row = int(bbox[0] * grid_size)\n            cell_size = 1 / grid_size\n            row_interval = (cell_size*row, cell_size*(row+1))\n            col_interval = (cell_size*col, cell_size*(col+1))\n\n            # if more than 2 bboxes in one cell then skip\n            if used_col_row[(row, col)] == 2:\n                continue\n\n            used_col_row[(row, col)] += 1\n\n            if used_col_row[(row, col)] == 1:\n                # bbox center coords relative to grid cell\n                fmap[0, row, col, 0]  = (bbox[0] - row_interval[0]) / (row_interval[1] - row_interval[0])\n                fmap[0, row, col, 1]  = (bbox[1] - col_interval[0]) / (col_interval[1] - col_interval[0])\n                fmap[0, row, col, 2:4]  = bbox[2:] # bbox w and h relative to image size\n                fmap[0, row, col, 4] = 1 # confindece\n            elif used_col_row[(row, col)] == 2:\n                # bbox center coords relative to grid cell\n                fmap[0, row, col, 5]  = (bbox[0] - row_interval[0]) / (row_interval[1] - row_interval[0])\n                fmap[0, row, col, 6]  = (bbox[1] - col_interval[0]) / (col_interval[1] - col_interval[0])\n                fmap[0, row, col, 7:9]  = bbox[2:] # bbox w and h relative to image size\n                fmap[0, row, col, 9] = 1 # confindece\n            # set classes probabilities\n            fmap[0, row, col, label - 1 + 10] = 1\n        gt.append(fmap)\n    \n    images = torch.cat(images, 0)\n    detections = torch.cat(gt, 0)\n    return (images, detections)","metadata":{"execution":{"iopub.status.busy":"2024-04-26T17:58:38.654381Z","iopub.execute_input":"2024-04-26T17:58:38.654665Z","iopub.status.idle":"2024-04-26T17:58:38.671400Z","shell.execute_reply.started":"2024-04-26T17:58:38.654636Z","shell.execute_reply":"2024-04-26T17:58:38.670666Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def convert_label_matrix_to_bboxes(label_matrix, S=7, C=5, B=2, img_size=448):\n    height, width, _ = label_matrix.shape\n\n    bboxes = []\n    predicted_classes = []\n    confidence = []\n\n    for i in range(height):\n        for j in range(width):\n            cell_label = label_matrix[i, j]\n\n            if cell_label[C] != 0:\n                cell_x, cell_y, width_cell, height_cell = cell_label[C+1:C+5]\n\n                xmin = (j + cell_x - width_cell / 2).item() / S * img_size\n                ymin = (i + cell_y - height_cell / 2).item() / S * img_size\n                xmax = (j + cell_x + width_cell / 2).item() / S * img_size\n                ymax = (i + cell_y + height_cell / 2).item() / S * img_size\n\n                bboxes.append([xmin, ymin, xmax, ymax])\n                predicted_classes.append(torch.argmax(cell_label[0:C]).item())\n                confidence.append(cell_label[C])\n\n    return np.array(bboxes), np.array(predicted_classes), np.array(confidence)","metadata":{"execution":{"iopub.status.busy":"2024-04-26T17:58:38.672334Z","iopub.execute_input":"2024-04-26T17:58:38.672606Z","iopub.status.idle":"2024-04-26T17:58:38.684533Z","shell.execute_reply.started":"2024-04-26T17:58:38.672584Z","shell.execute_reply":"2024-04-26T17:58:38.683791Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# cv_dir = os.getcwd()\n# data_dir = os.path.join(cv_dir, \"data\")\ndata_dir = 'kaggle/working/data'\nfo.config.dataset_zoo_dir = data_dir","metadata":{"execution":{"iopub.status.busy":"2024-04-26T17:58:38.685586Z","iopub.execute_input":"2024-04-26T17:58:38.685879Z","iopub.status.idle":"2024-04-26T17:58:38.696642Z","shell.execute_reply.started":"2024-04-26T17:58:38.685856Z","shell.execute_reply":"2024-04-26T17:58:38.695888Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def load_coco(max_samples):\n    dataset = foz.load_zoo_dataset(\n    \"coco-2017\",\n    splits = [\"train\", \"validation\", \"test\"],\n    label_types = [\"detections\"],\n    # classes = classes\n    max_samples = max_samples,\n    dataset_dir=\"../data\")\n    \n    dataset.compute_metadata()\n    return dataset","metadata":{"execution":{"iopub.status.busy":"2024-04-26T17:58:38.697689Z","iopub.execute_input":"2024-04-26T17:58:38.697960Z","iopub.status.idle":"2024-04-26T17:58:38.706042Z","shell.execute_reply.started":"2024-04-26T17:58:38.697937Z","shell.execute_reply":"2024-04-26T17:58:38.705287Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def ttsplit(dataset):\n    train_data = dataset.match_tags(\"train\")\n    test_data = dataset.match_tags(\"test\")\n    val_data = dataset.match_tags(\"validation\")\n    return train_data, test_data, val_data","metadata":{"execution":{"iopub.status.busy":"2024-04-26T17:58:38.707297Z","iopub.execute_input":"2024-04-26T17:58:38.708115Z","iopub.status.idle":"2024-04-26T17:58:38.715711Z","shell.execute_reply.started":"2024-04-26T17:58:38.708083Z","shell.execute_reply":"2024-04-26T17:58:38.714903Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def get_torch(dataset):\n    classes = dataset.distinct(\n    \"ground_truth.detections.label\"\n    )\n    torch_dataset = FiftyOneTorchDataset(dataset, transforms=Transformtsz(resize=(448, 448)), classes=classes)\n    return dataset","metadata":{"execution":{"iopub.status.busy":"2024-04-26T17:58:38.719773Z","iopub.execute_input":"2024-04-26T17:58:38.720161Z","iopub.status.idle":"2024-04-26T17:58:38.725044Z","shell.execute_reply.started":"2024-04-26T17:58:38.720131Z","shell.execute_reply":"2024-04-26T17:58:38.724197Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def get_loader(torch_dataset):\n    data_loader = torch.utils.data.DataLoader(torch_dataset, batch_size=1, shuffle=False)\n    return data_loader","metadata":{"execution":{"iopub.status.busy":"2024-04-26T17:58:38.726133Z","iopub.execute_input":"2024-04-26T17:58:38.726417Z","iopub.status.idle":"2024-04-26T17:58:38.733554Z","shell.execute_reply.started":"2024-04-26T17:58:38.726393Z","shell.execute_reply":"2024-04-26T17:58:38.732797Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"## Model","metadata":{}},{"cell_type":"code","source":"class YoloBackbone(nn.Module):\n    def __init__(self):\n        super(YoloBackbone, self).__init__()\n        conv1 = nn.Sequential(\n            nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3),\n            # nn.BatchNorm2d(64),\n            nn.LeakyReLU(0.1, inplace=True)\n        )\n        pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n        conv2 = nn.Sequential(\n            nn.Conv2d(64, 192, kernel_size=3, padding=1),\n            # nn.BatchNorm2d(192),\n            nn.LeakyReLU(0.1, inplace=True)\n        )\n        pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n        conv3 = nn.Sequential(\n            nn.Conv2d(192, 128, kernel_size=1),\n            # nn.BatchNorm2d(128),\n            nn.LeakyReLU(0.1, inplace=True),\n            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n            # nn.BatchNorm2d(256),\n            nn.LeakyReLU(0.1, inplace=True),\n            nn.Conv2d(256, 256, kernel_size=1),\n            # nn.BatchNorm2d(256),\n            nn.LeakyReLU(0.1, inplace=True),\n            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n            # nn.BatchNorm2d(512),\n            nn.LeakyReLU(0.1, inplace=True)\n        )\n        pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n\n        conv4_part = nn.Sequential(\n            nn.Conv2d(512, 256, kernel_size=1),\n            # nn.BatchNorm2d(256),\n            nn.LeakyReLU(0.1, inplace=True),\n            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n            # nn.BatchNorm2d(512),\n            nn.LeakyReLU(0.1, inplace=True)\n        )\n        conv4_modules = []\n        for _ in range(4):\n            conv4_modules.append(conv4_part)\n        conv4 = nn.Sequential(\n            *conv4_modules,\n            nn.Conv2d(512, 512, kernel_size=1),\n            # nn.BatchNorm2d(512),\n            nn.LeakyReLU(0.1, inplace=True),\n            nn.Conv2d(512, 1024, kernel_size=3, padding=1),\n            # nn.BatchNorm2d(1024),\n            nn.LeakyReLU(0.1, inplace=True)\n        )\n        pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n        conv5 = nn.Sequential(\n            nn.Conv2d(1024, 512, kernel_size=1),\n            # nn.BatchNorm2d(512),\n            nn.LeakyReLU(0.1, inplace=True),\n            nn.Conv2d(512, 1024, kernel_size=3, padding=1),\n            # nn.BatchNorm2d(1024),\n            nn.LeakyReLU(0.1, inplace=True),\n            nn.Conv2d(1024, 512, kernel_size=1),\n            # nn.BatchNorm2d(512),\n            nn.LeakyReLU(0.1, inplace=True),\n            nn.Conv2d(512, 1024, kernel_size=3, padding=1),\n            # nn.BatchNorm2d(1024),\n            nn.LeakyReLU(0.1, inplace=True)\n        )\n        self.net = nn.Sequential(conv1, pool1, conv2, pool2, conv3, pool3, conv4, pool4, conv5)\n\n    def forward(self, X):\n        return self.net(X)","metadata":{"execution":{"iopub.status.busy":"2024-04-26T17:58:38.734815Z","iopub.execute_input":"2024-04-26T17:58:38.735210Z","iopub.status.idle":"2024-04-26T17:58:38.750649Z","shell.execute_reply.started":"2024-04-26T17:58:38.735180Z","shell.execute_reply":"2024-04-26T17:58:38.749727Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"class Yolo(nn.Module):\n    def __init__(self, backbone: YoloBackbone = YoloBackbone(), backbone_out_channels=1024, n_classes=80):\n        self.n_classes = n_classes\n        super(Yolo, self).__init__()\n        self.backbone = backbone\n        self.head = nn.Sequential(\n            nn.Conv2d(backbone_out_channels, 1024, kernel_size=3, padding=1),\n            # nn.BatchNorm2d(1024),\n            nn.LeakyReLU(0.1, inplace=True),\n            nn.Conv2d(1024, 1024, kernel_size=3, padding=1, stride=2),\n            # nn.BatchNorm2d(1024),\n            nn.LeakyReLU(0.1, inplace=True),\n            nn.Conv2d(1024, 1024, kernel_size=3, padding=1),\n            # nn.BatchNorm2d(1024),\n            nn.LeakyReLU(0.1, inplace=True),\n            nn.Conv2d(1024, 1024, kernel_size=3, padding=1),\n            # nn.BatchNorm2d(1024),\n            nn.LeakyReLU(0.1, inplace=True),\n            nn.Flatten(),\n            nn.Linear(7*7*1024, 4096),\n            nn.Dropout(0.5),\n            nn.LeakyReLU(0.1, inplace=True),\n            nn.Linear(4096, 7 * 7 *(2 * 5 + self.n_classes)),\n            nn.Sigmoid(),\n            nn.Unflatten(1, (7, 7, (2 * 5 + self.n_classes)))\n        )\n        self.net = nn.Sequential(self.backbone, self.head)\n\n    def forward(self, X):\n        return self.net(X)","metadata":{"execution":{"iopub.status.busy":"2024-04-26T17:58:38.751686Z","iopub.execute_input":"2024-04-26T17:58:38.751948Z","iopub.status.idle":"2024-04-26T17:58:38.964554Z","shell.execute_reply.started":"2024-04-26T17:58:38.751927Z","shell.execute_reply":"2024-04-26T17:58:38.963561Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"## Utilis","metadata":{}},{"cell_type":"markdown","source":"#### IoU","metadata":{}},{"cell_type":"code","source":"def is_intersect(self, boxA, boxB):\n    if boxA[0] > boxB[2]:\n        return False  \n    if boxA[1] > boxB[3]:\n        return False  \n    if boxA[2] < boxB[0]:\n        return False \n    if boxA[3] < boxB[1]:\n        return False  \n    return True\n\n\ndef get_intersection(self, boxA, boxB):\n    xA = max(boxA[0], boxB[0])\n    yA = max(boxA[1], boxB[1])\n    xB = min(boxA[2], boxB[2])\n    yB = min(boxA[3], boxB[3])\n    return (xB - xA + 1) * (yB - yA + 1)\n\n\ndef get_union(self, boxA, boxB):\n    area_A = (boxA[2] - boxA[0] + 1) * (boxA[3] - boxA[1] + 1)\n    area_B = (boxB[2] - boxB[0] + 1) * (boxB[3] - boxB[1] + 1)\n    return area_A + area_B\n\n\ndef transform_x1y1wh_to_x1y1x2y2(self, box):\n    x1 = round(box[0], 2)\n    y1 = round(box[1], 2)\n    x2 = round(box[0] + box[2], 2)\n    y2 = round(box[1] + box[3], 2)\n    return [x1, y1, x2, y2]\n\n\ndef get_IoU(self, boxA, boxB):\n    # x1y1wh -> x1y1x2y2\n    boxA = self.transform_x1y1wh_to_x1y1x2y2(boxA)\n    boxB = self.transform_x1y1wh_to_x1y1x2y2(boxB)\n    if self.is_intersect(boxA, boxB) is False:\n        return 0\n    inter = self.get_intersection(boxA, boxB)\n    union = self.get_union(boxA, boxB)\n    iou = inter / (union - inter)\n    return iou","metadata":{"execution":{"iopub.status.busy":"2024-04-26T17:58:38.965765Z","iopub.execute_input":"2024-04-26T17:58:38.966070Z","iopub.status.idle":"2024-04-26T17:58:38.978268Z","shell.execute_reply.started":"2024-04-26T17:58:38.966044Z","shell.execute_reply":"2024-04-26T17:58:38.977403Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"#### Loss","metadata":{}},{"cell_type":"code","source":"def yolo_loss(yhat, y, lambda_coord=5, lambda_noobj=0.5, n_classes=80):\n    \"\"\"\n    Args:\n        yhat: [#, 7, 7, 30]\n        y: [#, 7, 7, 30]\n    Returns:\n        loss: [#]\n    \"\"\"\n    with torch.no_grad():\n        # arrange cell xidx, yidx\n        # [7, 7]\n        cell_xidx = (torch.arange(49) % 7).reshape(7, 7)\n        cell_yidx = (torch.div(torch.arange(49), 7, rounding_mode='floor')).reshape(7, 7)\n        # transform to [7, 7, 2]\n        cell_xidx.unsqueeze_(-1)\n        cell_yidx.unsqueeze_(-1)\n        cell_xidx.expand(7, 7, 2)\n        cell_yidx.expand(7, 7, 2)\n        # move to device\n        cell_xidx = cell_xidx.to(yhat.device)\n        cell_yidx = cell_yidx.to(yhat.device)\n\n    def calc_coord(val):\n        with torch.no_grad():\n            # transform cell relative coordinates to image relative coordinates\n            x = (val[..., 0] + cell_xidx) / 7.0\n            y = (val[..., 1] + cell_yidx) / 7.0\n\n            return (x - val[..., 2] / 2.0,\n                x + val[..., 2] / 2.0,\n                y - val[..., 3] / 2.0,\n                y + val[..., 3] / 2.0)\n\n    y_area = y[..., :10].reshape(-1, 7, 7, 2, 5)\n    yhat_area = yhat[..., :10].reshape(-1, 7, 7, 2, 5)\n\n    y_class = y[..., 10:].reshape(-1, 7, 7, n_classes)\n    yhat_class = yhat[..., 10:].reshape(-1, 7, 7, n_classes)\n\n    with torch.no_grad():\n        # calculate IoU\n        x_min, x_max, y_min, y_max = calc_coord(y_area)\n        x_min_hat, x_max_hat, y_min_hat, y_max_hat = calc_coord(yhat_area)\n\n        wi = torch.min(x_max, x_max_hat) - torch.max(x_min, x_min_hat)\n        wi = torch.max(wi, torch.zeros_like(wi))\n        hi = torch.min(y_max, y_max_hat) - torch.max(y_min, y_min_hat)\n        hi = torch.max(hi, torch.zeros_like(hi))\n\n        intersection = wi * hi\n        union = (x_max - x_min) * (y_max - y_min) + (x_max_hat - x_min_hat) * (y_max_hat - y_min_hat) - intersection\n        iou = intersection / (union + 1e-6) # add epsilon to avoid nan\n\n        _, res = iou.max(dim=3, keepdim=True)\n\n    # [#, 7, 7, 5]\n    # responsible bounding box (having higher IoU)\n    yhat_res = torch.take_along_dim(yhat_area, res.unsqueeze(3), 3).squeeze_(3)\n    y_res = y_area[..., 0, :5]\n\n    with torch.no_grad():\n        # calculate indicator matrix\n        have_obj = y_res[..., 4] > 0\n        no_obj = ~have_obj\n\n    return ((lambda_coord * ( # coordinate loss\n          (y_res[..., 0] - yhat_res[..., 0]) ** 2 # X\n        + (y_res[..., 1] - yhat_res[..., 1]) ** 2 # Y\n        + (torch.sqrt(y_res[..., 2]) - torch.sqrt(yhat_res[..., 2])) ** 2  # W\n        + (torch.sqrt(y_res[..., 3]) - torch.sqrt(yhat_res[..., 3])) ** 2) # H\n        # confidence\n        + (y_res[..., 4] - yhat_res[..., 4]) ** 2\n        # class\n        + ((y_class - yhat_class) ** 2).sum(dim=3)) * have_obj\n        # noobj\n        + ((y_area[..., 0, 4] - yhat_area[..., 0, 4]) ** 2 + \\\n        (y_area[..., 1, 4] - yhat_area[..., 1, 4]) ** 2) * no_obj * lambda_noobj).sum(dim=(1, 2))","metadata":{"execution":{"iopub.status.busy":"2024-04-26T17:58:38.980159Z","iopub.execute_input":"2024-04-26T17:58:38.980477Z","iopub.status.idle":"2024-04-26T17:58:39.000356Z","shell.execute_reply.started":"2024-04-26T17:58:38.980443Z","shell.execute_reply":"2024-04-26T17:58:38.999295Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"#### NMS","metadata":{}},{"cell_type":"code","source":"def nms(pred, threshold=0.5):\n\n    with torch.no_grad():\n        pred = pred.reshape((-1, 30))\n        nms_data = [[] for _ in range(20)]\n        for i in range(pred.shape[0]):\n            cell = pred[i]\n            score, idx = torch.max(cell[10:30], dim=0)\n            idx = idx.item()\n            x, y, w, h, iou = cell[0:5].cpu().numpy()\n\n            nms_data[idx].append([i, x, y, w, h, iou, score.item()])\n            x, y, w, h, iou = cell[5:10].cpu().numpy()\n            nms_data[idx].append([i, x, y, w, h, iou, score.item()])\n\n        ret = torch.zeros_like(pred)\n        flag = torch.zeros(pred.shape[0], dtype=torch.bool)\n        for c in range(20):\n            c_nms_data = np.array(nms_data[c])\n\n            keep_index = _nms(c_nms_data, threshold)\n            keeps = c_nms_data[keep_index]\n\n            for keep in keeps:\n                i, x, y, w, h, iou, score = keep\n                i = int(i)\n\n                last_score, _ = torch.max(ret[i][10:30], dim=0)\n                last_iou = ret[i][4]\n\n                if score * iou > last_score * last_iou:\n                    flag[i] = False\n                if flag[i]: continue\n\n                ret[i][0:5] = torch.tensor([x, y, w, h, iou])\n                ret[i][10:30] = 0\n                ret[i][10 + c] = score\n\n                flag[i] = True\n\n        return ret\n    \n    \ndef _nms(data, threshold):\n\n    if len(data) == 0:\n        return []\n\n    cell_idx = data[:, 0]\n    x = data[:, 1]\n    y = data[:, 2]\n    xidx = cell_idx % 7\n    yidx = cell_idx // 7\n    x = (x + xidx) / 7.0\n    y = (y + yidx) / 7.0\n    w = data[:, 3]\n    h = data[:, 4]\n    x1 = x - w / 2\n    y1 = y - h / 2\n    x2 = x + w / 2\n    y2 = y + h / 2\n\n    score_area = data[:, 5]\n\n    areas = w * h\n\n    order = score_area.argsort()[::-1]\n    keep = []\n\n    while order.size > 0:\n        i = order[0]\n        keep.append(i)\n        xx1 = np.maximum(x1[i], x1[order[1:]])\n        yy1 = np.maximum(y1[i], y1[order[1:]])\n        xx2 = np.minimum(x2[i], x2[order[1:]])\n        yy2 = np.minimum(y2[i], y2[order[1:]])\n\n        w = np.maximum(0.0, xx2 - xx1)\n        h = np.maximum(0.0, yy2 - yy1)\n        inter = w * h\n        ovr = inter / (areas[i] + areas[order[1:]] - inter)\n\n        inds = np.where(ovr <= threshold)[0]\n        order = order[inds + 1]\n\n    return keep","metadata":{"execution":{"iopub.status.busy":"2024-04-26T17:58:39.001752Z","iopub.execute_input":"2024-04-26T17:58:39.002353Z","iopub.status.idle":"2024-04-26T17:58:39.022545Z","shell.execute_reply.started":"2024-04-26T17:58:39.002318Z","shell.execute_reply":"2024-04-26T17:58:39.021533Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"#### mAP","metadata":{}},{"cell_type":"code","source":"def calculate_mAP(self, classAP_data):\n    AP_50_per_class, PR_50_pts_per_class = {}, {}\n    (\n        num_true_per_class,\n        num_positive_per_class,\n        num_TP_50_per_class,\n        num_FP_50_per_class,\n    ) = ({}, {}, {}, {})\n    mAP_50, mAP_75, mAP_5095 = 0, 0, 0\n    valid_num_classes = 0 + 1e-8\n\n    for res in classAP_data:\n        if res[\"total_positive\"] > 0:\n            valid_num_classes += 1\n            AP_50_per_class[res[\"class\"]] = res[\"AP_50\"]\n            PR_50_pts_per_class[res[\"class\"]] = {\n                \"mprec\": res[\"prec_50\"],\n                \"mrec\": res[\"rec_50\"],\n            }\n            num_true_per_class[res[\"class\"]] = res[\"total_true\"]\n            num_positive_per_class[res[\"class\"]] = res[\"total_positive\"]\n            num_TP_50_per_class[res[\"class\"]] = res[\"total_TP_50\"]\n            num_FP_50_per_class[res[\"class\"]] = res[\"total_FP_50\"]\n            mAP_50 += res[\"AP_50\"]\n            mAP_75 += res[\"AP_75\"]\n            mAP_5095 += res[\"AP_5095\"]\n\n    mAP_50 /= valid_num_classes\n    mAP_75 /= valid_num_classes\n    mAP_5095 /= valid_num_classes\n\n    res = {\n        \"AP_50_PER_CLASS\": AP_50_per_class,\n        \"PR_50_PTS_PER_CLASS\": PR_50_pts_per_class,\n        \"NUM_TRUE_PER_CLASS\": num_true_per_class,\n        \"NUM_POSITIVE_PER_CLASS\": num_positive_per_class,\n        \"NUM_TP_50_PER_CLASS\": num_TP_50_per_class,\n        \"NUM_FP_50_PER_CLASS\": num_FP_50_per_class,\n        \"mAP_50\": round(mAP_50, 4),\n        \"mAP_75\": round(mAP_75, 4),\n        \"mAP_5095\": round(mAP_5095, 4),\n    }\n    return res","metadata":{"execution":{"iopub.status.busy":"2024-04-26T17:58:39.023767Z","iopub.execute_input":"2024-04-26T17:58:39.024071Z","iopub.status.idle":"2024-04-26T17:58:39.036681Z","shell.execute_reply.started":"2024-04-26T17:58:39.024046Z","shell.execute_reply":"2024-04-26T17:58:39.035758Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"#### Weights initialization","metadata":{}},{"cell_type":"code","source":"def weight_init(m):\n    '''\n    Usage:\n        model = Model()\n        model.apply(weight_init)\n    '''\n    if isinstance(m, nn.Conv1d):\n        init.normal_(m.weight.data)\n        if m.bias is not None:\n            init.normal_(m.bias.data)\n    elif isinstance(m, nn.Conv2d):\n        init.xavier_normal_(m.weight.data)\n        if m.bias is not None:\n            init.normal_(m.bias.data)\n    elif isinstance(m, nn.Conv3d):\n        init.xavier_normal_(m.weight.data)\n        if m.bias is not None:\n            init.normal_(m.bias.data)\n    elif isinstance(m, nn.ConvTranspose1d):\n        init.normal_(m.weight.data)\n        if m.bias is not None:\n            init.normal_(m.bias.data)\n    elif isinstance(m, nn.ConvTranspose2d):\n        init.xavier_normal_(m.weight.data)\n        if m.bias is not None:\n            init.normal_(m.bias.data)\n    elif isinstance(m, nn.ConvTranspose3d):\n        init.xavier_normal_(m.weight.data)\n        if m.bias is not None:\n            init.normal_(m.bias.data)\n    elif isinstance(m, nn.BatchNorm1d):\n        init.normal_(m.weight.data, mean=1, std=0.02)\n        init.constant_(m.bias.data, 0)\n    elif isinstance(m, nn.BatchNorm2d):\n        init.normal_(m.weight.data, mean=1, std=0.02)\n        init.constant_(m.bias.data, 0)\n    elif isinstance(m, nn.BatchNorm3d):\n        init.normal_(m.weight.data, mean=1, std=0.02)\n        init.constant_(m.bias.data, 0)\n    elif isinstance(m, nn.Linear):\n        init.xavier_normal_(m.weight.data)\n        init.normal_(m.bias.data)\n    elif isinstance(m, nn.LSTM):\n        for param in m.parameters():\n            if len(param.shape) >= 2:\n                init.orthogonal_(param.data)\n            else:\n                init.normal_(param.data)\n    elif isinstance(m, nn.LSTMCell):\n        for param in m.parameters():\n            if len(param.shape) >= 2:\n                init.orthogonal_(param.data)\n            else:\n                init.normal_(param.data)\n    elif isinstance(m, nn.GRU):\n        for param in m.parameters():\n            if len(param.shape) >= 2:\n                init.orthogonal_(param.data)\n            else:\n                init.normal_(param.data)\n    elif isinstance(m, nn.GRUCell):\n        for param in m.parameters():\n            if len(param.shape) >= 2:\n                init.orthogonal_(param.data)\n            else:\n                init.normal_(param.data)","metadata":{"execution":{"iopub.status.busy":"2024-04-26T17:58:39.038024Z","iopub.execute_input":"2024-04-26T17:58:39.038340Z","iopub.status.idle":"2024-04-26T17:58:39.056181Z","shell.execute_reply.started":"2024-04-26T17:58:39.038295Z","shell.execute_reply":"2024-04-26T17:58:39.054960Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"#### Other","metadata":{}},{"cell_type":"code","source":"class Accumulator(object):\n    \"\"\"\n    Sum a list of numbers over time\n    from: https://github.com/dsgiitr/d2l-pytorch/blob/master/d2l/base.py\n    \"\"\"\n    def __init__(self, n):\n        self.data = [0.0] * n\n    def add(self, *args):\n        self.data = [a + b for a, b in zip(self.data, args)]\n    def reset(self):\n        self.data = [0] * len(self.data)\n    def __getitem__(self, i):\n        return self.data[i]\n","metadata":{"execution":{"iopub.status.busy":"2024-04-26T17:58:39.058265Z","iopub.execute_input":"2024-04-26T17:58:39.058585Z","iopub.status.idle":"2024-04-26T17:58:39.069034Z","shell.execute_reply.started":"2024-04-26T17:58:39.058560Z","shell.execute_reply":"2024-04-26T17:58:39.068054Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"class Timer(object):\n    \"\"\"Record multiple running times.\"\"\"\n    def __init__(self):\n        self.times = []\n        self.start()\n\n    def start(self):\n        \"\"\"Start the timer\"\"\"\n        self.start_time = time.time()\n\n    def stop(self):\n        \"\"\"Stop the timer and record the time in a list\"\"\"\n        self.times.append(time.time() - self.start_time)\n        return self.times[-1]\n\n    def avg(self):\n        \"\"\"Return the average time\"\"\"\n        return sum(self.times)/len(self.times)\n\n    def sum(self):\n        \"\"\"Return the sum of time\"\"\"\n        return sum(self.times)\n\n    def cumsum(self):\n        \"\"\"Return the accumuated times\"\"\"\n        return np.array(self.times).cumsum().tolist()","metadata":{"execution":{"iopub.status.busy":"2024-04-26T17:58:39.069970Z","iopub.execute_input":"2024-04-26T17:58:39.070229Z","iopub.status.idle":"2024-04-26T17:58:39.082194Z","shell.execute_reply.started":"2024-04-26T17:58:39.070206Z","shell.execute_reply":"2024-04-26T17:58:39.081337Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"## Train","metadata":{}},{"cell_type":"code","source":"def train(net, train_iter, test_iter, num_epochs, lr, momentum=0.9, weight_decay=5e-4, accum_batch_num=1, save_path='./chkpt', load=None, load_epoch=-1, pretrained=False):\n    '''\n    Train net work. Some notes for load & load_epoch:\n    :param load: the file of model weights to load\n    :param load_epoch: num of epoch already completed (minus 1). should be the same with the number in auto-saved file name.\n    '''\n\n    def print_and_log(msg, log_file):\n        print(msg)\n        with open(log_file, 'a', encoding='utf8') as f:\n            f.write(msg + '\\n')\n\n    def update_lr(opt, lr):\n        for param_group in opt.param_groups:\n            param_group['lr'] = lr\n\n    os.makedirs(save_path, exist_ok=True)\n    log_file = os.path.join(save_path, f'log-{time.time_ns()}.txt')\n\n    if load:\n        net.load_state_dict(torch.load(load))\n    elif pretrained:\n        net.head.apply(weight_init)\n    else:\n        # init params\n        net.apply(weight_init)\n\n    if not torch.cuda.is_available():\n        net = net.to(torch.device('cpu'))\n        devices = [torch.device('cpu')]\n    else:\n        net = net.to(torch.device('cuda'))\n        devices = [torch.device('cuda')]\n\n    # define optimizer\n    if isinstance(lr, float):\n        tlr = lr\n    else: tlr = 0.001\n\n    optimizer = torch.optim.SGD(net.parameters(), lr=tlr, momentum=momentum, weight_decay=weight_decay)\n\n    # visualization\n\n    num_batches = len(train_iter)\n    # train\n    for epoch in range(num_epochs - load_epoch - 1):\n        # adjust true epoch number according to pre_load\n        epoch = epoch + load_epoch + 1\n\n        # define metrics: train loss, sample count\n        metrics = Accumulator(2)\n        # define timer\n        timer = Timer()\n\n        # train\n        net.train()\n\n        # set batch accumulator\n        accum_cnt = 0\n        accum = 0\n        loop = tqdm(train_iter, leave=True)\n\n        for batch_idx, (X, y) in enumerate(loop):\n            timer.start()\n\n            X, y = X.to(devices[0]), y.to(devices[0])\n            yhat = net(X)\n            \n            loss_val = yolo_loss(yhat, y)\n            # print(loss_val)\n\n            # backward to accumulate gradients\n            loss_val.sum().backward()\n            # step\n            optimizer.step()\n            # clear\n            optimizer.zero_grad()\n\n\n            # update metrics\n            with torch.no_grad():\n                metrics.add(loss_val.sum().cpu(), X.shape[0])\n            train_l = м[0] / metrics[1]\n\n            timer.stop()\n\n            # log & visualization\n            if (batch_idx + 1) % (num_batches // 5) == 0 or batch_idx == num_batches - 1:\n                print_and_log(\"epoch: %d, batch: %d / %d, loss: %.4f, time: %.4f\" % (epoch, batch_idx + 1, num_batches, train_l.item(), timer.sum()), log_file)\n\n        # redefine metrics: test loss, test sample count\n        metrics = Accumulator(2)\n        # redefine timer\n        timer = Timer()\n        # test\n        net.eval()\n\n        with torch.no_grad():\n            timer.start()\n\n            for batch in test_iter:\n                X, y = batch\n                X, y = X.to(devices[0]), y.to(devices[0])\n                yhat = net(X)\n\n                loss_val = yolo_loss(yhat, y)\n                metrics.add(loss_val.sum().cpu(), X.shape[0])\n\n            timer.stop()\n\n            test_l = metrics[0] / metrics[1]\n            print_and_log(\"epoch: %d, test loss: %.4f, time: %.4f\" % (epoch + 1, test_l.item(), timer.sum()), log_file)\n\n        # save model\n        if epoch % 5 == 0:\n            torch.save(net.state_dict(), os.path.join(save_path, f'./{time.time_ns()}-epoch-{epoch}.pth'))","metadata":{"execution":{"iopub.status.busy":"2024-04-26T17:58:39.083480Z","iopub.execute_input":"2024-04-26T17:58:39.083761Z","iopub.status.idle":"2024-04-26T17:58:39.103538Z","shell.execute_reply.started":"2024-04-26T17:58:39.083738Z","shell.execute_reply":"2024-04-26T17:58:39.102656Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"dataset = load_coco(15000)\nclasses = dataset.distinct(\"ground_truth.detections.label\")\ntrain_data = dataset.match_tags(\"train\")\ntest_data = dataset.match_tags(\"test\")\nval_data = dataset.match_tags(\"validation\")\ntrain_dataset = FiftyOneTorchDataset(train_data, transforms=Transformtsz(resize=(448, 448)), classes=classes)\nval_dataset_test = FiftyOneTorchDataset(val_data, transforms=Transformtsz(resize=(448, 448)), classes=classes)\ntest_dataset_test = FiftyOneTorchDataset(test_data, transforms=Transformtsz(resize=(448, 448)), classes=classes)\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=8, shuffle=False, collate_fn=collate)#, sampler=train_sampler)\nval_loader = torch.utils.data.DataLoader(val_dataset_test, batch_size=8, shuffle=False, collate_fn=collate)#, sampler=train_sampler)\ntest_loader = torch.utils.data.DataLoader(test_dataset_test, batch_size=8, shuffle=False, collate_fn=collate)#, sampler=train_sampler)","metadata":{"execution":{"iopub.status.busy":"2024-04-26T17:58:39.104669Z","iopub.execute_input":"2024-04-26T17:58:39.104927Z","iopub.status.idle":"2024-04-26T20:49:04.153396Z","shell.execute_reply.started":"2024-04-26T17:58:39.104904Z","shell.execute_reply":"2024-04-26T20:49:04.152626Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Downloading split 'train' to '../data/train' if necessary\nDownloading annotations to '../data/tmp-download/annotations_trainval2017.zip'\n 100% |██████|    1.9Gb/1.9Gb [25.2s elapsed, 0s remaining, 89.4Mb/s]      \nExtracting annotations to '../data/raw/instances_train2017.json'\nDownloading 15000 images\n 100% |██████████████| 15000/15000 [1.2h elapsed, 0s remaining, 3.7 images/s]      \nWriting annotations for 15000 downloaded samples to '../data/train/labels.json'\nDownloading split 'validation' to '../data/validation' if necessary\nFound annotations at '../data/raw/instances_val2017.json'\nOnly found 5000 (<15000) samples matching your requirements\nDownloading 5000 images\n 100% |████████████████| 5000/5000 [23.9m elapsed, 0s remaining, 3.2 images/s]      \nWriting annotations to '../data/validation/labels.json'\nDownloading split 'test' to '../data/test' if necessary\nDownloading test info to '../data/tmp-download/image_info_test2017.zip'\n 100% |██████|    8.7Mb/8.7Mb [1.2s elapsed, 0s remaining, 7.3Mb/s]      \nExtracting test info to '../data/raw/image_info_test2017.json'\nDownloading 15000 images\n 100% |██████████████| 15000/15000 [1.2h elapsed, 0s remaining, 3.2 images/s]      \nWriting annotations for 15000 downloaded samples to '../data/test/labels.json'\nDataset info written to '../data/info.json'\nLoading 'coco-2017' split 'train'\n 100% |█████████████| 15000/15000 [1.8m elapsed, 0s remaining, 121.9 samples/s]      \nLoading 'coco-2017' split 'validation'\n 100% |███████████████| 5000/5000 [36.2s elapsed, 0s remaining, 149.8 samples/s]      \nLoading 'coco-2017' split 'test'\n 100% |█████████████| 15000/15000 [6.6s elapsed, 0s remaining, 2.2K samples/s]      \nDataset 'coco-2017-train-validation-test-15000' created\n","output_type":"stream"}]},{"cell_type":"code","source":"resnet18 = torchvision.models.resnet18(pretrained=True)\n# net = Yolo() # classical YoloV1 with our backbone\n# resnet 18 backbone\n# remove avg pool and fc\nresnet18 = models.resnet18(weights=ResNet18_Weights.DEFAULT)\nbackbone = nn.Sequential(*list(resnet18.children())[:-2])\nfor param in backbone.parameters():\n    param.requires_grad = False\nnet = Yolo(backbone, backbone_out_channels=512)","metadata":{"execution":{"iopub.status.busy":"2024-04-26T20:49:04.154506Z","iopub.execute_input":"2024-04-26T20:49:04.154796Z","iopub.status.idle":"2024-04-26T20:49:07.153143Z","shell.execute_reply.started":"2024-04-26T20:49:04.154771Z","shell.execute_reply":"2024-04-26T20:49:07.152331Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n100%|██████████| 44.7M/44.7M [00:00<00:00, 162MB/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"train(net, train_iter=train_loader, test_iter=test_loader, num_epochs=20, lr=0.0001)","metadata":{"execution":{"iopub.status.busy":"2024-04-26T20:49:07.154332Z","iopub.execute_input":"2024-04-26T20:49:07.154687Z","iopub.status.idle":"2024-04-27T00:25:27.842399Z","shell.execute_reply.started":"2024-04-26T20:49:07.154654Z","shell.execute_reply":"2024-04-27T00:25:27.841423Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stderr","text":" 20%|██        | 375/1875 [01:25<05:29,  4.55it/s]","output_type":"stream"},{"name":"stdout","text":"epoch: 0, batch: 375 / 1875, loss: 26.5950, time: 38.7382\n","output_type":"stream"},{"name":"stderr","text":" 40%|████      | 750/1875 [02:49<04:06,  4.56it/s]","output_type":"stream"},{"name":"stdout","text":"epoch: 0, batch: 750 / 1875, loss: 22.7513, time: 76.3947\n","output_type":"stream"},{"name":"stderr","text":" 60%|██████    | 1125/1875 [04:12<02:57,  4.22it/s]","output_type":"stream"},{"name":"stdout","text":"epoch: 0, batch: 1125 / 1875, loss: 21.1903, time: 114.0551\n","output_type":"stream"},{"name":"stderr","text":" 80%|████████  | 1500/1875 [05:36<01:22,  4.56it/s]","output_type":"stream"},{"name":"stdout","text":"epoch: 0, batch: 1500 / 1875, loss: 20.3507, time: 151.7104\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1875/1875 [07:01<00:00,  4.45it/s]","output_type":"stream"},{"name":"stdout","text":"epoch: 0, batch: 1875 / 1875, loss: 19.7499, time: 189.3596\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"epoch: 1, test loss: 1.2301, time: 220.4817\n","output_type":"stream"},{"name":"stderr","text":" 20%|██        | 375/1875 [01:24<05:33,  4.50it/s]","output_type":"stream"},{"name":"stdout","text":"epoch: 1, batch: 375 / 1875, loss: 16.7412, time: 37.7510\n","output_type":"stream"},{"name":"stderr","text":" 40%|████      | 750/1875 [02:49<04:06,  4.57it/s]","output_type":"stream"},{"name":"stdout","text":"epoch: 1, batch: 750 / 1875, loss: 16.7124, time: 75.4732\n","output_type":"stream"},{"name":"stderr","text":" 60%|██████    | 1125/1875 [04:13<02:53,  4.33it/s]","output_type":"stream"},{"name":"stdout","text":"epoch: 1, batch: 1125 / 1875, loss: 16.6695, time: 113.1397\n","output_type":"stream"},{"name":"stderr","text":" 80%|████████  | 1500/1875 [05:37<01:22,  4.52it/s]","output_type":"stream"},{"name":"stdout","text":"epoch: 1, batch: 1500 / 1875, loss: 16.6768, time: 150.8107\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1875/1875 [07:01<00:00,  4.45it/s]","output_type":"stream"},{"name":"stdout","text":"epoch: 1, batch: 1875 / 1875, loss: 16.6126, time: 188.4809\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"epoch: 2, test loss: 1.5125, time: 219.2541\n","output_type":"stream"},{"name":"stderr","text":" 20%|██        | 375/1875 [01:24<05:32,  4.52it/s]","output_type":"stream"},{"name":"stdout","text":"epoch: 2, batch: 375 / 1875, loss: 15.8871, time: 37.7097\n","output_type":"stream"},{"name":"stderr","text":" 40%|████      | 750/1875 [02:51<04:14,  4.42it/s]","output_type":"stream"},{"name":"stdout","text":"epoch: 2, batch: 750 / 1875, loss: 15.8619, time: 75.4531\n","output_type":"stream"},{"name":"stderr","text":" 60%|██████    | 1125/1875 [04:17<03:02,  4.11it/s]","output_type":"stream"},{"name":"stdout","text":"epoch: 2, batch: 1125 / 1875, loss: 15.8560, time: 113.1955\n","output_type":"stream"},{"name":"stderr","text":" 80%|████████  | 1500/1875 [05:43<01:27,  4.27it/s]","output_type":"stream"},{"name":"stdout","text":"epoch: 2, batch: 1500 / 1875, loss: 15.8722, time: 150.9049\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1875/1875 [07:08<00:00,  4.37it/s]","output_type":"stream"},{"name":"stdout","text":"epoch: 2, batch: 1875 / 1875, loss: 15.8280, time: 188.5896\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"epoch: 3, test loss: 1.4395, time: 225.9683\n","output_type":"stream"},{"name":"stderr","text":" 20%|██        | 375/1875 [01:25<05:31,  4.52it/s]","output_type":"stream"},{"name":"stdout","text":"epoch: 3, batch: 375 / 1875, loss: 15.2734, time: 37.7147\n","output_type":"stream"},{"name":"stderr","text":" 40%|████      | 750/1875 [02:50<04:09,  4.51it/s]","output_type":"stream"},{"name":"stdout","text":"epoch: 3, batch: 750 / 1875, loss: 15.2330, time: 75.4075\n","output_type":"stream"},{"name":"stderr","text":" 60%|██████    | 1125/1875 [04:15<02:56,  4.24it/s]","output_type":"stream"},{"name":"stdout","text":"epoch: 3, batch: 1125 / 1875, loss: 15.2229, time: 113.1227\n","output_type":"stream"},{"name":"stderr","text":" 80%|████████  | 1500/1875 [05:41<01:23,  4.47it/s]","output_type":"stream"},{"name":"stdout","text":"epoch: 3, batch: 1500 / 1875, loss: 15.2561, time: 150.8377\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1875/1875 [07:06<00:00,  4.39it/s]","output_type":"stream"},{"name":"stdout","text":"epoch: 3, batch: 1875 / 1875, loss: 15.2238, time: 188.5411\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"epoch: 4, test loss: 1.3887, time: 221.1122\n","output_type":"stream"},{"name":"stderr","text":" 20%|██        | 376/1875 [01:23<05:23,  4.64it/s]","output_type":"stream"},{"name":"stdout","text":"epoch: 4, batch: 375 / 1875, loss: 14.7298, time: 37.6912\n","output_type":"stream"},{"name":"stderr","text":" 40%|████      | 750/1875 [02:46<04:01,  4.65it/s]","output_type":"stream"},{"name":"stdout","text":"epoch: 4, batch: 750 / 1875, loss: 14.7022, time: 75.3975\n","output_type":"stream"},{"name":"stderr","text":" 60%|██████    | 1125/1875 [04:10<02:53,  4.32it/s]","output_type":"stream"},{"name":"stdout","text":"epoch: 4, batch: 1125 / 1875, loss: 14.6982, time: 113.0731\n","output_type":"stream"},{"name":"stderr","text":" 80%|████████  | 1500/1875 [05:33<01:22,  4.55it/s]","output_type":"stream"},{"name":"stdout","text":"epoch: 4, batch: 1500 / 1875, loss: 14.7342, time: 150.7421\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1875/1875 [06:57<00:00,  4.49it/s]","output_type":"stream"},{"name":"stdout","text":"epoch: 4, batch: 1875 / 1875, loss: 14.7111, time: 188.4185\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"epoch: 5, test loss: 1.4034, time: 216.7491\n","output_type":"stream"},{"name":"stderr","text":" 20%|██        | 376/1875 [01:23<05:20,  4.68it/s]","output_type":"stream"},{"name":"stdout","text":"epoch: 5, batch: 375 / 1875, loss: 14.1965, time: 37.6877\n","output_type":"stream"},{"name":"stderr","text":" 40%|████      | 750/1875 [02:47<04:01,  4.66it/s]","output_type":"stream"},{"name":"stdout","text":"epoch: 5, batch: 750 / 1875, loss: 14.1853, time: 75.3826\n","output_type":"stream"},{"name":"stderr","text":" 60%|██████    | 1125/1875 [04:12<02:56,  4.24it/s]","output_type":"stream"},{"name":"stdout","text":"epoch: 5, batch: 1125 / 1875, loss: 14.1937, time: 113.1324\n","output_type":"stream"},{"name":"stderr","text":" 80%|████████  | 1500/1875 [05:36<01:24,  4.46it/s]","output_type":"stream"},{"name":"stdout","text":"epoch: 5, batch: 1500 / 1875, loss: 14.2165, time: 150.8490\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1875/1875 [07:00<00:00,  4.46it/s]","output_type":"stream"},{"name":"stdout","text":"epoch: 5, batch: 1875 / 1875, loss: 14.1850, time: 188.5651\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"epoch: 6, test loss: 1.2671, time: 219.5629\n","output_type":"stream"},{"name":"stderr","text":" 20%|██        | 375/1875 [01:24<05:46,  4.33it/s]","output_type":"stream"},{"name":"stdout","text":"epoch: 6, batch: 375 / 1875, loss: 13.6476, time: 37.7044\n","output_type":"stream"},{"name":"stderr","text":" 40%|████      | 750/1875 [02:49<04:14,  4.42it/s]","output_type":"stream"},{"name":"stdout","text":"epoch: 6, batch: 750 / 1875, loss: 13.6511, time: 75.4018\n","output_type":"stream"},{"name":"stderr","text":" 60%|██████    | 1125/1875 [04:13<02:56,  4.26it/s]","output_type":"stream"},{"name":"stdout","text":"epoch: 6, batch: 1125 / 1875, loss: 13.6484, time: 113.1099\n","output_type":"stream"},{"name":"stderr","text":" 80%|████████  | 1500/1875 [05:38<01:25,  4.41it/s]","output_type":"stream"},{"name":"stdout","text":"epoch: 6, batch: 1500 / 1875, loss: 13.6700, time: 150.8013\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1875/1875 [07:04<00:00,  4.42it/s]","output_type":"stream"},{"name":"stdout","text":"epoch: 6, batch: 1875 / 1875, loss: 13.6287, time: 188.4923\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"epoch: 7, test loss: 1.5945, time: 222.0629\n","output_type":"stream"},{"name":"stderr","text":" 20%|██        | 375/1875 [01:24<05:34,  4.48it/s]","output_type":"stream"},{"name":"stdout","text":"epoch: 7, batch: 375 / 1875, loss: 13.0064, time: 37.7087\n","output_type":"stream"},{"name":"stderr","text":" 40%|████      | 750/1875 [02:49<04:06,  4.57it/s]","output_type":"stream"},{"name":"stdout","text":"epoch: 7, batch: 750 / 1875, loss: 13.0207, time: 75.4104\n","output_type":"stream"},{"name":"stderr","text":" 60%|██████    | 1125/1875 [04:14<02:57,  4.22it/s]","output_type":"stream"},{"name":"stdout","text":"epoch: 7, batch: 1125 / 1875, loss: 13.0131, time: 113.1062\n","output_type":"stream"},{"name":"stderr","text":" 80%|████████  | 1500/1875 [05:39<01:23,  4.48it/s]","output_type":"stream"},{"name":"stdout","text":"epoch: 7, batch: 1500 / 1875, loss: 13.0160, time: 150.8046\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1875/1875 [07:04<00:00,  4.42it/s]","output_type":"stream"},{"name":"stdout","text":"epoch: 7, batch: 1875 / 1875, loss: 12.9822, time: 188.4873\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"epoch: 8, test loss: 1.4992, time: 224.3858\n","output_type":"stream"},{"name":"stderr","text":" 20%|██        | 375/1875 [01:25<06:19,  3.95it/s]","output_type":"stream"},{"name":"stdout","text":"epoch: 8, batch: 375 / 1875, loss: 12.4072, time: 37.7889\n","output_type":"stream"},{"name":"stderr","text":" 40%|████      | 750/1875 [02:50<04:08,  4.54it/s]","output_type":"stream"},{"name":"stdout","text":"epoch: 8, batch: 750 / 1875, loss: 12.4097, time: 75.5434\n","output_type":"stream"},{"name":"stderr","text":" 60%|██████    | 1125/1875 [04:15<02:58,  4.20it/s]","output_type":"stream"},{"name":"stdout","text":"epoch: 8, batch: 1125 / 1875, loss: 12.3744, time: 113.2977\n","output_type":"stream"},{"name":"stderr","text":" 80%|████████  | 1500/1875 [05:40<01:23,  4.51it/s]","output_type":"stream"},{"name":"stdout","text":"epoch: 8, batch: 1500 / 1875, loss: 12.3819, time: 151.0654\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1875/1875 [07:05<00:00,  4.41it/s]","output_type":"stream"},{"name":"stdout","text":"epoch: 8, batch: 1875 / 1875, loss: 12.3554, time: 188.8161\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"epoch: 9, test loss: 1.1576, time: 228.3315\n","output_type":"stream"},{"name":"stderr","text":" 20%|██        | 375/1875 [01:25<05:38,  4.44it/s]","output_type":"stream"},{"name":"stdout","text":"epoch: 9, batch: 375 / 1875, loss: 11.8119, time: 37.7240\n","output_type":"stream"},{"name":"stderr","text":" 40%|████      | 750/1875 [02:50<04:12,  4.46it/s]","output_type":"stream"},{"name":"stdout","text":"epoch: 9, batch: 750 / 1875, loss: 11.8059, time: 75.4182\n","output_type":"stream"},{"name":"stderr","text":" 60%|██████    | 1125/1875 [04:16<02:59,  4.18it/s]","output_type":"stream"},{"name":"stdout","text":"epoch: 9, batch: 1125 / 1875, loss: 11.7419, time: 113.1295\n","output_type":"stream"},{"name":"stderr","text":" 80%|████████  | 1500/1875 [05:42<01:25,  4.38it/s]","output_type":"stream"},{"name":"stdout","text":"epoch: 9, batch: 1500 / 1875, loss: 11.7307, time: 150.8525\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1875/1875 [07:08<00:00,  4.37it/s]","output_type":"stream"},{"name":"stdout","text":"epoch: 9, batch: 1875 / 1875, loss: 11.7060, time: 188.5428\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"epoch: 10, test loss: 1.4366, time: 218.8023\n","output_type":"stream"},{"name":"stderr","text":" 20%|██        | 376/1875 [01:24<05:24,  4.62it/s]","output_type":"stream"},{"name":"stdout","text":"epoch: 10, batch: 375 / 1875, loss: 11.1820, time: 37.7131\n","output_type":"stream"},{"name":"stderr","text":" 40%|████      | 750/1875 [02:48<04:07,  4.54it/s]","output_type":"stream"},{"name":"stdout","text":"epoch: 10, batch: 750 / 1875, loss: 11.1804, time: 75.4171\n","output_type":"stream"},{"name":"stderr","text":" 60%|██████    | 1125/1875 [04:13<03:00,  4.15it/s]","output_type":"stream"},{"name":"stdout","text":"epoch: 10, batch: 1125 / 1875, loss: 11.1257, time: 113.1230\n","output_type":"stream"},{"name":"stderr","text":" 80%|████████  | 1500/1875 [05:37<01:23,  4.46it/s]","output_type":"stream"},{"name":"stdout","text":"epoch: 10, batch: 1500 / 1875, loss: 11.1225, time: 150.8188\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1875/1875 [07:01<00:00,  4.44it/s]","output_type":"stream"},{"name":"stdout","text":"epoch: 10, batch: 1875 / 1875, loss: 11.0998, time: 188.5148\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"epoch: 11, test loss: 1.3512, time: 223.3095\n","output_type":"stream"},{"name":"stderr","text":" 20%|██        | 376/1875 [01:24<05:22,  4.65it/s]","output_type":"stream"},{"name":"stdout","text":"epoch: 11, batch: 375 / 1875, loss: 10.5244, time: 37.6937\n","output_type":"stream"},{"name":"stderr","text":" 40%|████      | 750/1875 [02:48<04:04,  4.60it/s]","output_type":"stream"},{"name":"stdout","text":"epoch: 11, batch: 750 / 1875, loss: 10.5222, time: 75.3627\n","output_type":"stream"},{"name":"stderr","text":" 60%|██████    | 1125/1875 [04:12<02:53,  4.31it/s]","output_type":"stream"},{"name":"stdout","text":"epoch: 11, batch: 1125 / 1875, loss: 10.4879, time: 113.0423\n","output_type":"stream"},{"name":"stderr","text":" 80%|████████  | 1500/1875 [05:36<01:23,  4.48it/s]","output_type":"stream"},{"name":"stdout","text":"epoch: 11, batch: 1500 / 1875, loss: 10.4757, time: 150.7205\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1875/1875 [07:01<00:00,  4.45it/s]","output_type":"stream"},{"name":"stdout","text":"epoch: 11, batch: 1875 / 1875, loss: 10.4488, time: 188.3961\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"epoch: 12, test loss: 1.2267, time: 226.9250\n","output_type":"stream"},{"name":"stderr","text":" 20%|██        | 376/1875 [01:25<05:27,  4.58it/s]","output_type":"stream"},{"name":"stdout","text":"epoch: 12, batch: 375 / 1875, loss: 9.9832, time: 37.6839\n","output_type":"stream"},{"name":"stderr","text":" 40%|████      | 750/1875 [02:49<04:01,  4.65it/s]","output_type":"stream"},{"name":"stdout","text":"epoch: 12, batch: 750 / 1875, loss: 9.9460, time: 75.3547\n","output_type":"stream"},{"name":"stderr","text":" 60%|██████    | 1125/1875 [04:13<02:59,  4.17it/s]","output_type":"stream"},{"name":"stdout","text":"epoch: 12, batch: 1125 / 1875, loss: 9.8934, time: 113.0390\n","output_type":"stream"},{"name":"stderr","text":" 80%|████████  | 1500/1875 [05:39<01:23,  4.48it/s]","output_type":"stream"},{"name":"stdout","text":"epoch: 12, batch: 1500 / 1875, loss: 9.8939, time: 150.7392\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1875/1875 [07:05<00:00,  4.41it/s]","output_type":"stream"},{"name":"stdout","text":"epoch: 12, batch: 1875 / 1875, loss: 9.8660, time: 188.4513\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"epoch: 13, test loss: 1.1241, time: 221.6296\n","output_type":"stream"},{"name":"stderr","text":" 20%|██        | 376/1875 [01:24<05:24,  4.62it/s]","output_type":"stream"},{"name":"stdout","text":"epoch: 13, batch: 375 / 1875, loss: 9.4638, time: 37.7281\n","output_type":"stream"},{"name":"stderr","text":" 40%|████      | 750/1875 [02:49<04:06,  4.55it/s]","output_type":"stream"},{"name":"stdout","text":"epoch: 13, batch: 750 / 1875, loss: 9.4218, time: 75.4926\n","output_type":"stream"},{"name":"stderr","text":" 60%|██████    | 1125/1875 [04:14<02:58,  4.21it/s]","output_type":"stream"},{"name":"stdout","text":"epoch: 13, batch: 1125 / 1875, loss: 9.3802, time: 113.2690\n","output_type":"stream"},{"name":"stderr","text":" 80%|████████  | 1500/1875 [05:40<01:23,  4.47it/s]","output_type":"stream"},{"name":"stdout","text":"epoch: 13, batch: 1500 / 1875, loss: 9.3655, time: 151.0611\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1875/1875 [07:06<00:00,  4.40it/s]","output_type":"stream"},{"name":"stdout","text":"epoch: 13, batch: 1875 / 1875, loss: 9.3580, time: 188.8165\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"epoch: 14, test loss: 1.1532, time: 221.2494\n","output_type":"stream"},{"name":"stderr","text":" 20%|██        | 376/1875 [01:25<05:24,  4.61it/s]","output_type":"stream"},{"name":"stdout","text":"epoch: 14, batch: 375 / 1875, loss: 8.9780, time: 37.7616\n","output_type":"stream"},{"name":"stderr","text":" 40%|████      | 750/1875 [02:49<04:06,  4.57it/s]","output_type":"stream"},{"name":"stdout","text":"epoch: 14, batch: 750 / 1875, loss: 8.9126, time: 75.5145\n","output_type":"stream"},{"name":"stderr","text":" 60%|██████    | 1125/1875 [04:13<03:00,  4.14it/s]","output_type":"stream"},{"name":"stdout","text":"epoch: 14, batch: 1125 / 1875, loss: 8.8770, time: 113.2643\n","output_type":"stream"},{"name":"stderr","text":" 80%|████████  | 1500/1875 [05:38<01:24,  4.45it/s]","output_type":"stream"},{"name":"stdout","text":"epoch: 14, batch: 1500 / 1875, loss: 8.8737, time: 150.9995\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1875/1875 [07:02<00:00,  4.43it/s]","output_type":"stream"},{"name":"stdout","text":"epoch: 14, batch: 1875 / 1875, loss: 8.8499, time: 188.7653\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"epoch: 15, test loss: 1.0816, time: 226.7203\n","output_type":"stream"},{"name":"stderr","text":" 20%|██        | 376/1875 [01:25<05:29,  4.56it/s]","output_type":"stream"},{"name":"stdout","text":"epoch: 15, batch: 375 / 1875, loss: 8.4887, time: 37.7797\n","output_type":"stream"},{"name":"stderr","text":" 40%|████      | 750/1875 [02:50<04:05,  4.58it/s]","output_type":"stream"},{"name":"stdout","text":"epoch: 15, batch: 750 / 1875, loss: 8.4311, time: 75.5588\n","output_type":"stream"},{"name":"stderr","text":" 60%|██████    | 1125/1875 [04:15<02:57,  4.23it/s]","output_type":"stream"},{"name":"stdout","text":"epoch: 15, batch: 1125 / 1875, loss: 8.3863, time: 113.3236\n","output_type":"stream"},{"name":"stderr","text":" 80%|████████  | 1500/1875 [05:40<01:23,  4.49it/s]","output_type":"stream"},{"name":"stdout","text":"epoch: 15, batch: 1500 / 1875, loss: 8.3838, time: 151.0781\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1875/1875 [07:06<00:00,  4.40it/s]","output_type":"stream"},{"name":"stdout","text":"epoch: 15, batch: 1875 / 1875, loss: 8.3670, time: 188.8618\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"epoch: 16, test loss: 1.4844, time: 229.2741\n","output_type":"stream"},{"name":"stderr","text":" 20%|██        | 375/1875 [01:27<05:49,  4.30it/s]","output_type":"stream"},{"name":"stdout","text":"epoch: 16, batch: 375 / 1875, loss: 8.0128, time: 37.8016\n","output_type":"stream"},{"name":"stderr","text":" 40%|████      | 750/1875 [02:54<04:19,  4.33it/s]","output_type":"stream"},{"name":"stdout","text":"epoch: 16, batch: 750 / 1875, loss: 7.9905, time: 75.5544\n","output_type":"stream"},{"name":"stderr","text":" 60%|██████    | 1125/1875 [04:19<03:03,  4.09it/s]","output_type":"stream"},{"name":"stdout","text":"epoch: 16, batch: 1125 / 1875, loss: 7.9617, time: 113.3044\n","output_type":"stream"},{"name":"stderr","text":" 80%|████████  | 1500/1875 [05:45<01:23,  4.47it/s]","output_type":"stream"},{"name":"stdout","text":"epoch: 16, batch: 1500 / 1875, loss: 7.9715, time: 151.0359\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1875/1875 [07:12<00:00,  4.34it/s]","output_type":"stream"},{"name":"stdout","text":"epoch: 16, batch: 1875 / 1875, loss: 7.9542, time: 188.7770\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"epoch: 17, test loss: 1.7891, time: 225.1311\n","output_type":"stream"},{"name":"stderr","text":" 20%|██        | 375/1875 [01:25<05:45,  4.35it/s]","output_type":"stream"},{"name":"stdout","text":"epoch: 17, batch: 375 / 1875, loss: 7.6247, time: 37.7419\n","output_type":"stream"},{"name":"stderr","text":" 40%|████      | 750/1875 [02:51<04:06,  4.56it/s]","output_type":"stream"},{"name":"stdout","text":"epoch: 17, batch: 750 / 1875, loss: 7.5995, time: 75.4765\n","output_type":"stream"},{"name":"stderr","text":" 60%|██████    | 1125/1875 [04:19<03:05,  4.03it/s]","output_type":"stream"},{"name":"stdout","text":"epoch: 17, batch: 1125 / 1875, loss: 7.5604, time: 113.2825\n","output_type":"stream"},{"name":"stderr","text":" 80%|████████  | 1500/1875 [05:47<01:27,  4.28it/s]","output_type":"stream"},{"name":"stdout","text":"epoch: 17, batch: 1500 / 1875, loss: 7.5612, time: 151.0857\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1875/1875 [07:16<00:00,  4.30it/s]","output_type":"stream"},{"name":"stdout","text":"epoch: 17, batch: 1875 / 1875, loss: 7.5469, time: 188.8973\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"epoch: 18, test loss: 1.5897, time: 229.0345\n","output_type":"stream"},{"name":"stderr","text":" 20%|██        | 376/1875 [01:24<05:24,  4.61it/s]","output_type":"stream"},{"name":"stdout","text":"epoch: 18, batch: 375 / 1875, loss: 7.2280, time: 37.7211\n","output_type":"stream"},{"name":"stderr","text":" 40%|████      | 750/1875 [02:49<04:09,  4.51it/s]","output_type":"stream"},{"name":"stdout","text":"epoch: 18, batch: 750 / 1875, loss: 7.2170, time: 75.4251\n","output_type":"stream"},{"name":"stderr","text":" 60%|██████    | 1125/1875 [04:13<02:55,  4.27it/s]","output_type":"stream"},{"name":"stdout","text":"epoch: 18, batch: 1125 / 1875, loss: 7.1930, time: 113.1131\n","output_type":"stream"},{"name":"stderr","text":" 80%|████████  | 1500/1875 [05:37<01:23,  4.48it/s]","output_type":"stream"},{"name":"stdout","text":"epoch: 18, batch: 1500 / 1875, loss: 7.2018, time: 150.8188\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1875/1875 [07:02<00:00,  4.43it/s]","output_type":"stream"},{"name":"stdout","text":"epoch: 18, batch: 1875 / 1875, loss: 7.1811, time: 188.5402\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"epoch: 19, test loss: 1.4600, time: 227.5802\n","output_type":"stream"},{"name":"stderr","text":" 20%|██        | 376/1875 [01:23<05:18,  4.70it/s]","output_type":"stream"},{"name":"stdout","text":"epoch: 19, batch: 375 / 1875, loss: 6.8707, time: 37.7243\n","output_type":"stream"},{"name":"stderr","text":" 40%|████      | 750/1875 [02:47<04:06,  4.56it/s]","output_type":"stream"},{"name":"stdout","text":"epoch: 19, batch: 750 / 1875, loss: 6.8480, time: 75.4433\n","output_type":"stream"},{"name":"stderr","text":" 60%|██████    | 1125/1875 [04:11<02:54,  4.30it/s]","output_type":"stream"},{"name":"stdout","text":"epoch: 19, batch: 1125 / 1875, loss: 6.8354, time: 113.1430\n","output_type":"stream"},{"name":"stderr","text":" 80%|████████  | 1500/1875 [05:35<01:34,  3.99it/s]","output_type":"stream"},{"name":"stdout","text":"epoch: 19, batch: 1500 / 1875, loss: 6.8450, time: 150.8881\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1875/1875 [07:02<00:00,  4.44it/s]","output_type":"stream"},{"name":"stdout","text":"epoch: 19, batch: 1875 / 1875, loss: 6.8414, time: 188.6944\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"epoch: 20, test loss: 1.5931, time: 223.1350\n","output_type":"stream"}]},{"cell_type":"code","source":"!zip -r coco15k.zip kaggle/working/data\ndisplay(FileLink('coco15k.zip'))","metadata":{"execution":{"iopub.status.busy":"2024-04-27T00:28:17.451282Z","iopub.execute_input":"2024-04-27T00:28:17.451695Z","iopub.status.idle":"2024-04-27T00:28:18.907566Z","shell.execute_reply.started":"2024-04-27T00:28:17.451666Z","shell.execute_reply":"2024-04-27T00:28:18.906158Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"\tzip warning: name not matched: kaggle/working/data\n\nzip error: Nothing to do! (try: zip -r coco15k.zip . -i kaggle/working/data)\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[26], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzip -r coco15k.zip kaggle/working/data\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m display(\u001b[43mFileLink\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoco15k.zip\u001b[39m\u001b[38;5;124m'\u001b[39m))\n","\u001b[0;31mNameError\u001b[0m: name 'FileLink' is not defined"],"ename":"NameError","evalue":"name 'FileLink' is not defined","output_type":"error"}]},{"cell_type":"markdown","source":"## Testing","metadata":{}},{"cell_type":"code","source":"class ObjectDetectionMetricsCalculator():\n\n    def __init__(self, num_classes: int, confidence_thres: float):\n\n        # initialize data\n        self.data = [{\"data\": [], \"detection\": 0, \"truth\": 0} for _ in range(num_classes)]\n        self.confidence_thres = confidence_thres\n\n\n    def add_image_data(self, pred: torch.Tensor, truth: str):\n\n        pred = pred.reshape(-1, 30)\n        truth = json.loads(truth)\n\n        choose_truth_index = [None for _ in range(pred.shape[0])]\n        iou = [0 for _ in range(pred.shape[0])]\n\n        for i in range(pred.shape[0]):\n            score, cat = pred[i][10:30].max(dim=0)\n            confidence = pred[i][4]\n            # filter by confidence threshold\n            if confidence * score < self.confidence_thres: continue\n            \n            x, y, w, h = pred[i][0:4]\n            # calculate cell index\n            xidx = i % 7\n            yidx = i // 7\n            # transform cell relative coordinates to image relative coordinates\n            xhat = (x + xidx) / 7.0\n            yhat = (y + yidx) / 7.0\n\n            xmin_hat = xhat - w / 2\n            xmax_hat = xhat + w / 2\n            ymin_hat = yhat - h / 2\n            ymax_hat = yhat + h / 2\n\n            for j in range(len(truth)):\n                bbox = truth[j]\n                # judge whether is same class\n                if cat != bbox['category']: continue\n                # calculate IoU\n                xmin, ymin, xmax, ymax = bbox['xmin'], bbox['ymin'], bbox['xmax'], bbox['ymax']\n                wi = min(xmax, xmax_hat) - max(xmin, xmin_hat)\n                wi = max(wi, 0)\n                hi = min(ymax, ymax_hat) - max(ymin, ymin_hat)\n                hi = max(hi, 0)\n                intersection = wi * hi\n                union = (xmax - xmin) * (ymax - ymin) + (xmax_hat - xmin_hat) * (ymax_hat - ymin_hat) - intersection\n                this_iou = intersection / (union + 1e-6)\n                # determine whether to choose this ground truth\n                if iou[i] is None: choose = True\n                elif iou[i] < this_iou: choose = True\n                else: choose = False\n                # if choose, assign value\n                if choose:\n                    iou[i] = this_iou\n                    choose_truth_index[i] = j\n        # init a bool array for judging mustbe_FP later\n        truth_chosen = [False for _ in range(len(truth))]\n        # sort according to IoU\n        sort_idx = np.argsort(iou)[::-1]\n        # add into metrics\n        for i in sort_idx:\n            score, cat = pred[i][10:30].max(dim=0)\n            confidence = pred[i][4]\n            # filter by confidence threshold\n            if confidence * score < self.confidence_thres: continue\n\n            truth_index = choose_truth_index[i]\n            if truth_index == None: \n                mustbe_FP = True\n                is_difficult = False\n            elif truth_chosen[truth_index]:\n                mustbe_FP = True\n                is_difficult = truth[choose_truth_index[i]]['difficult']\n            else: \n                mustbe_FP = False\n                truth_chosen[choose_truth_index[i]] = True\n                is_difficult = truth[choose_truth_index[i]]['difficult']\n\n            self.data[cat]['data'].append(CalculationMetrics(iou[i], float(confidence * score), mustbe_FP, is_difficult))\n\n            # update detection statistics\n            self.data[cat]['detection'] += 1\n        # update ground truth statistics\n        for bbox in truth:\n            if bbox['difficult']: continue\n            self.data[bbox['category']]['truth'] += 1\n\n\n    def calculate_precision_recall(self, iou_thres: float, class_idx: int) -> list:\n\n        ret = []\n        # retrieve count\n        truth_cnt = self.data[class_idx]['truth']\n        # accumulated TP\n        acc_TP = 0\n        # accumulated difficult count\n        acc_difficult = 0\n        # sort metrics by confidence\n        data = sorted(self.data[class_idx]['data'], key=cmp_to_key(compare_metrics))\n        for i, metrics in enumerate(data):\n            if metrics.IoU >= iou_thres and not metrics.mustbe_FP and not metrics.is_difficult:\n                acc_TP += 1\n            if metrics.is_difficult:\n                acc_difficult += 1\n            if i + 1 - acc_difficult > 0:\n                ret.append({\n                    'precision': acc_TP / (i + 1 - acc_difficult),\n                    'recall': acc_TP / truth_cnt\n                })\n        \n        return ret\n\n\n    def calculate_average_precision(self, iou_thres: float, class_idx: int, itpl_option: InterpolationMethod) -> float:\n\n        prl = self.calculate_precision_recall(iou_thres=iou_thres, class_idx=class_idx)\n\n        if itpl_option == InterpolationMethod.Interpolation_11:\n            intp_pts = [0.1 * i for i in range(11)]\n        elif itpl_option == InterpolationMethod.Interpolation_101:\n            intp_pts = [0.01 * i for i in range(101)]\n        else:\n            raise Exception('Unknown Interpolation Method')\n\n        max_dict = {}\n        gmax = 0\n\n        for pr in prl[::-1]:\n            gmax = max(gmax, pr['precision'])\n            max_dict[pr['recall']] = gmax\n\n        if len(max_dict) < 1: return 0.\n\n        max_keys = max_dict.keys()\n        max_keys = sorted(max_keys)\n\n        key_ptr = len(max_keys) - 2\n        last_key = max_keys[-1]\n\n        AP = 0\n\n        for query in intp_pts[::-1]:\n            if key_ptr < 0:\n                if query > last_key:\n                    ans = 0\n                else:\n                    ans = max_dict[last_key]\n            else:\n                if query > last_key:\n                    ans = 0\n                elif query > max_keys[key_ptr]:\n                    ans = max_dict[last_key]\n                else:\n                    while key_ptr >= 0:\n                        if query > max_keys[key_ptr]:\n                            break\n                        last_key = max_keys[key_ptr]\n                        key_ptr -= 1\n                    ans = max_dict[last_key]\n            AP += ans\n\n        AP /= len(intp_pts)\n        return AP\n\n\n    def calculate_mAP(self, iou_thres: float, itpl_option: InterpolationMethod) -> float:\n\n        mAP = 0\n        for c in range(len(self.data)):\n            mAP += self.calculate_average_precision(iou_thres, c, itpl_option)\n        mAP /= len(self.data)\n\n        return mAP\n\n\n    def calculate_COCOmAP(self) -> float:\n        \"\"\"calculate COCO mAP: expand AP@.5 and AP@.75. IoU thres from .5 to .95\n\n        Returns:\n            float: COCO mAP\n        \"\"\"\n        ious = [0.5 + 0.05 * i for i in range(10)]\n        coco_map = 0\n        for iou in ious:\n            coco_map += self.calculate_mAP(iou, InterpolationMethod.Interpolation_101)\n        coco_map /= len(ious)\n        return coco_map","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test(net, batch_size):\n  \n    lines = []\n    with open(test_index, 'r') as f:\n        for line in f.readlines():\n            line = line.strip()\n            lines.append(line)\n\n    with torch.no_grad():\n        idx = 0\n        while idx < len(lines):\n            to_idx = min(len(lines), idx + batch_size)\n            batch_lines = lines[idx:to_idx]\n            idx = to_idx\n\n            X = torch.Tensor([])\n            X = X.to('cuda')\n\n            S = torch.Tensor([])\n            S = S.to('cuda')\n\n            for line in batch_lines:\n                image_name = line + '.jpg'\n                this_path = os.path.join(image_path, image_name)\n\n                with Image.open(this_path) as img:\n                    s = torch.Tensor([float(img.size[0]), float(img.size[1])])\n                    s = s.to('cuda')\n                    S = torch.cat((S, s.unsqueeze_(0)), 0)\n\n                    rimg = torchvision.transforms.functional.resize(img, (448, 448))\n                    t = torchvision.transforms.ToTensor()(rimg).to('cuda')\n                    X = torch.cat((X, t.unsqueeze_(0)), 0)\n\n            YHat = net(X)\n            for i, yhat in enumerate(YHat):\n        # nms\n                yhat = nms(yhat)\n\n                yhat = yhat.reshape((-1, 30))\n                W = S[i][0]\n                H = S[i][1]\n\n                category_detected = [False for _ in range(20)]\n\n                for j in range(yhat.shape[0]):\n                    x, y, w, h, iou = yhat[j][0:5]\n\n                    # calculate cell index\n                    xidx = j % 7\n                    yidx = j // 7\n\n                    # transform cell relative coordinates to image relative coordinates\n                    x = (x + xidx) / 7.0\n                    y = (y + yidx) / 7.0\n\n                    score, cat = yhat[j][10:30].max(dim=0)\n                    if iou * score < 0.1: continue\n\n                    file_name = f'comp_det_test_{categories[cat]}.txt'\n                    file_path = os.path.join(results_dir, file_name)\n\n                    category_detected[cat] = True\n\n                    with open(file_path, 'a+', encoding='utf-8', newline='\\n') as f:\n                        x1 = max(1, int((x - w / 2) * W))\n                        y1 = max(1, int((y - h / 2) * H))\n                        x2 = min(int(W), int((x + w / 2) * W))\n                        y2 = min(int(H), int((y + h / 2) * H))\n                        conf = round(float(score * iou), 6)\n                        f.write(f'{batch_lines[i]} {conf} {x1}.000000 {y1}.000000 {x2}.000000 {y2}.000000\\n')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test_and_draw_mAP(net: torch.nn.Module, test_iter_raw: data.DataLoader, device: torch.device):\n\n    with torch.no_grad():\n        net.eval()\n        net.to(device)\n\n        # metrics calculation\n        calc = ObjectDetectionMetricsCalculator(20, 0.1)\n\n        for i, (X, YRaw) in enumerate(test_iter_raw):\n            print(\"Batch %d / %d\" % (i, len(test_iter_raw)))\n            display.clear_output(wait=True)\n            \n            X = X.to(device)\n            YHat = net(X)\n            for yhat, yraw in zip(YHat, YRaw):\n                yhat = nms(yhat)\n                calc.add_image_data(yhat.cpu(), yraw)\n\n        print(\"Test COCO mAP:\", calc.calculate_COCOmAP())\n\n        for i in range(20):\n            draw_precision_recall(calc.calculate_precision_recall(0.5, i), i)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_weight_path = '/kaggle/working/chkpt/1714178438389879385-epoch-20.pth'\ncategories = test_dataset_test.distinct(\"ground_truth.detections.label\")\ntest_index = '/kaggle/working/data/test/labels.json'\nimage_path = '/kaggle/working/data/test/data'\nos.makedirs('/kaggle/working/results', exist_ok=True)\nresults_dir = '/kaggle/working/results'\n\nresnet18 = torchvision.models.resnet18(pretrained=True)\nbackbone = nn.Sequential(*list(resnet18.children())[:-2])\nnet = Yolo(backbone, backbone_out_channels=512)\n\nnet.to('cuda')\nnet.load_state_dict(torch.load(model_weight_path))\nnet.eval()\n  \ntest(net, 64)\ntest_and_draw_mAP(net, test_iter_raw, 'cuda')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}